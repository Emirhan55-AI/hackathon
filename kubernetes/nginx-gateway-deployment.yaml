# Nginx API Gateway - Kubernetes Deployment and Service
# Reverse proxy and load balancer for all Aura AI microservices

apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-gateway-deployment
  namespace: aura-ai
  labels:
    app.kubernetes.io/name: nginx-gateway
    app.kubernetes.io/instance: production
    app.kubernetes.io/version: "1.25"
    app.kubernetes.io/component: api-gateway
    app.kubernetes.io/part-of: aura-ai-platform
    app.kubernetes.io/managed-by: kubernetes
spec:
  replicas: 3  # Multiple replicas for HA
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 1
  selector:
    matchLabels:
      app: nginx-gateway
  template:
    metadata:
      labels:
        app: nginx-gateway
        app.kubernetes.io/name: nginx-gateway
        app.kubernetes.io/component: api-gateway
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9113"
        prometheus.io/path: "/metrics"
    spec:
      serviceAccountName: aura-ai-service-account
      securityContext:
        runAsNonRoot: true
        runAsUser: 101  # Nginx user
        runAsGroup: 101
        fsGroup: 101

      containers:
      - name: nginx-gateway
        image: nginx:1.25-alpine
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 80
          name: http
          protocol: TCP
        - containerPort: 443
          name: https
          protocol: TCP
        
        volumeMounts:
        - name: nginx-config
          mountPath: /etc/nginx/nginx.conf
          subPath: nginx.conf
          readOnly: true
        - name: nginx-cache
          mountPath: /var/cache/nginx
        - name: nginx-logs
          mountPath: /var/log/nginx
        
        resources:
          requests:
            cpu: 500m
            memory: 512Mi
          limits:
            cpu: 1000m
            memory: 1Gi
        
        livenessProbe:
          httpGet:
            path: /health
            port: 80
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        
        readinessProbe:
          httpGet:
            path: /health
            port: 80
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 3
          successThreshold: 1
          failureThreshold: 3
        
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
          capabilities:
            drop:
            - ALL
            add:
            - NET_BIND_SERVICE  # Required to bind to port 80/443
        
        lifecycle:
          preStop:
            exec:
              command:
              - /bin/sh
              - -c
              - "sleep 10"

      # Nginx Prometheus Exporter sidecar
      - name: nginx-exporter
        image: nginx/nginx-prometheus-exporter:0.11.0
        imagePullPolicy: IfNotPresent
        args:
        - -nginx.scrape-uri=http://localhost:8080/nginx_status
        - -web.listen-address=:9113
        ports:
        - containerPort: 9113
          name: metrics
          protocol: TCP
        
        resources:
          requests:
            cpu: 50m
            memory: 64Mi
          limits:
            cpu: 100m
            memory: 128Mi
        
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
          capabilities:
            drop:
            - ALL

      volumes:
      - name: nginx-config
        configMap:
          name: nginx-config
      - name: nginx-cache
        emptyDir:
          sizeLimit: 1Gi
      - name: nginx-logs
        persistentVolumeClaim:
          claimName: logs-pvc

      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - nginx-gateway
              topologyKey: kubernetes.io/hostname

---
# Nginx Gateway Service
apiVersion: v1
kind: Service
metadata:
  name: nginx-gateway-service
  namespace: aura-ai
  labels:
    app.kubernetes.io/name: nginx-gateway
    app.kubernetes.io/component: service
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "9113"
    prometheus.io/path: "/metrics"
spec:
  type: ClusterIP
  selector:
    app: nginx-gateway
  ports:
  - name: http
    port: 80
    targetPort: 80
    protocol: TCP
  - name: https
    port: 443
    targetPort: 443
    protocol: TCP
  - name: metrics
    port: 9113
    targetPort: 9113
    protocol: TCP

---
# Horizontal Pod Autoscaler for Nginx Gateway
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: nginx-gateway-hpa
  namespace: aura-ai
  labels:
    app.kubernetes.io/name: nginx-gateway
    app.kubernetes.io/component: autoscaler
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: nginx-gateway-deployment
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 25
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 100
        periodSeconds: 60
      - type: Pods
        value: 3
        periodSeconds: 60
      selectPolicy: Max

---
# Updated Nginx ConfigMap with status endpoint for metrics
apiVersion: v1
kind: ConfigMap
metadata:
  name: nginx-config-with-metrics
  namespace: aura-ai
  labels:
    app.kubernetes.io/name: nginx-gateway
    app.kubernetes.io/component: config
data:
  nginx.conf: |
    user nginx;
    worker_processes auto;
    error_log /var/log/nginx/error.log notice;
    pid /var/run/nginx.pid;

    events {
        worker_connections 1024;
        use epoll;
        multi_accept on;
    }

    http {
        include /etc/nginx/mime.types;
        default_type application/octet-stream;
        
        log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                        '$status $body_bytes_sent "$http_referer" '
                        '"$http_user_agent" "$http_x_forwarded_for" '
                        'upstream: $upstream_addr response_time: $upstream_response_time';
                        
        access_log /var/log/nginx/access.log main;
        
        sendfile on;
        tcp_nopush on;
        tcp_nodelay on;
        keepalive_timeout 65;
        client_max_body_size 10M;
        
        gzip on;
        gzip_vary on;
        gzip_min_length 1000;
        gzip_types
            application/atom+xml
            application/geo+json
            application/javascript
            application/x-javascript
            application/json
            application/ld+json
            application/manifest+json
            application/rdf+xml
            application/rss+xml
            application/xhtml+xml
            application/xml
            font/eot
            font/otf
            font/ttf
            image/svg+xml
            text/css
            text/javascript
            text/plain
            text/xml;

        upstream visual_analysis_service {
            server visual-analysis-service.aura-ai.svc.cluster.local:8000;
            keepalive 32;
        }
        
        upstream outfit_recommendation_service {
            server outfit-recommendation-service.aura-ai.svc.cluster.local:8001;
            keepalive 32;
        }
        
        upstream conversational_ai_service {
            server conversational-ai-service.aura-ai.svc.cluster.local:8003;
            keepalive 32;
        }
        
        upstream triton_service {
            server triton-service.aura-ai.svc.cluster.local:8000;
            keepalive 32;
        }

        limit_req_zone $binary_remote_addr zone=api_limit:10m rate=100r/m;
        limit_req_zone $binary_remote_addr zone=upload_limit:10m rate=10r/m;

        # Status server for metrics
        server {
            listen 8080;
            server_name localhost;
            
            location /nginx_status {
                stub_status on;
                access_log off;
                allow 127.0.0.1;
                allow 10.0.0.0/8;
                allow 172.16.0.0/12;
                allow 192.168.0.0/16;
                deny all;
            }
        }

        # Main server
        server {
            listen 80;
            server_name _;
            
            add_header X-Frame-Options "SAMEORIGIN" always;
            add_header X-Content-Type-Options "nosniff" always;
            add_header X-XSS-Protection "1; mode=block" always;
            add_header Referrer-Policy "no-referrer-when-downgrade" always;
            
            location / {
                return 200 '{"service":"Aura AI Platform API Gateway","version":"1.0.0","status":"active","microservices":{"visual_analysis":"/api/v1/visual-analysis","outfit_recommendation":"/api/v1/outfit-recommendation","conversational_ai":"/api/v1/conversational-ai","triton":"/api/v1/triton"},"docs":{"visual_analysis":"http://localhost/api/v1/visual-analysis/docs","outfit_recommendation":"http://localhost/api/v1/outfit-recommendation/docs","conversational_ai":"http://localhost/api/v1/conversational-ai/docs"}}';
                add_header Content-Type application/json;
            }
            
            location /health {
                access_log off;
                return 200 '{"status":"healthy","gateway":"nginx","timestamp":"$time_iso8601"}';
                add_header Content-Type application/json;
            }

            location /api/v1/visual-analysis/ {
                limit_req zone=api_limit burst=20 nodelay;
                limit_req zone=upload_limit burst=5 nodelay;
                
                proxy_pass http://visual_analysis_service/;
                proxy_http_version 1.1;
                proxy_set_header Upgrade $http_upgrade;
                proxy_set_header Connection 'upgrade';
                proxy_set_header Host $host;
                proxy_set_header X-Real-IP $remote_addr;
                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
                proxy_set_header X-Forwarded-Proto $scheme;
                proxy_cache_bypass $http_upgrade;
                
                proxy_connect_timeout 30s;
                proxy_send_timeout 300s;
                proxy_read_timeout 300s;
            }

            location /api/v1/outfit-recommendation/ {
                limit_req zone=api_limit burst=20 nodelay;
                
                proxy_pass http://outfit_recommendation_service/;
                proxy_http_version 1.1;
                proxy_set_header Upgrade $http_upgrade;
                proxy_set_header Connection 'upgrade';
                proxy_set_header Host $host;
                proxy_set_header X-Real-IP $remote_addr;
                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
                proxy_set_header X-Forwarded-Proto $scheme;
                proxy_cache_bypass $http_upgrade;
                
                proxy_connect_timeout 30s;
                proxy_send_timeout 120s;
                proxy_read_timeout 120s;
            }

            location /api/v1/conversational-ai/ {
                limit_req zone=api_limit burst=20 nodelay;
                
                proxy_pass http://conversational_ai_service/;
                proxy_http_version 1.1;
                proxy_set_header Upgrade $http_upgrade;
                proxy_set_header Connection 'upgrade';
                proxy_set_header Host $host;
                proxy_set_header X-Real-IP $remote_addr;
                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
                proxy_set_header X-Forwarded-Proto $scheme;
                proxy_cache_bypass $http_upgrade;
                
                proxy_connect_timeout 30s;
                proxy_send_timeout 120s;
                proxy_read_timeout 120s;
            }

            location /api/v1/conversational-ai/ws/ {
                proxy_pass http://conversational_ai_service/ws/;
                proxy_http_version 1.1;
                proxy_set_header Upgrade $http_upgrade;
                proxy_set_header Connection "upgrade";
                proxy_set_header Host $host;
                proxy_set_header X-Real-IP $remote_addr;
                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
                proxy_set_header X-Forwarded-Proto $scheme;
                
                proxy_read_timeout 3600s;
                proxy_send_timeout 3600s;
            }

            location /api/v1/triton/ {
                limit_req zone=api_limit burst=30 nodelay;
                
                proxy_pass http://triton_service/;
                proxy_http_version 1.1;
                proxy_set_header Host $host;
                proxy_set_header X-Real-IP $remote_addr;
                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
                proxy_set_header X-Forwarded-Proto $scheme;
                
                proxy_connect_timeout 15s;
                proxy_send_timeout 60s;
                proxy_read_timeout 60s;
            }

            location /docs {
                return 302 /api/v1/visual-analysis/docs;
            }
            
            location /redoc {
                return 302 /api/v1/visual-analysis/redoc;
            }

            error_page 404 /404.html;
            error_page 500 502 503 504 /50x.html;
            
            location = /404.html {
                internal;
                return 404 '{"error":"Not Found","message":"The requested endpoint does not exist","available_endpoints":["/api/v1/visual-analysis","/api/v1/outfit-recommendation","/api/v1/conversational-ai","/api/v1/triton"]}';
                add_header Content-Type application/json;
            }
            
            location = /50x.html {
                internal;
                return 500 '{"error":"Internal Server Error","message":"One of the microservices is temporarily unavailable","retry_after":"30s"}';
                add_header Content-Type application/json;
            }
        }
    }
