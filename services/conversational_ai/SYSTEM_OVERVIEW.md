"""
Aura Conversational AI - RAG Service Documentation
================================================

## ğŸ¯ System Overview

Hibrit QLoRA + RAG Sistemi baÅŸarÄ±yla oluÅŸturuldu! Bu sistem, aÅŸaÄŸÄ±daki bileÅŸenleri iÃ§erir:

### ğŸ“ Dosya YapÄ±sÄ±
```
conversational_ai/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ finetune.py               # QLoRA fine-tuning (880+ lines) âœ…
â”‚   â”œâ”€â”€ build_vector_store.py     # Vector store builder (900+ lines) âœ…
â”‚   â”œâ”€â”€ rag_service.py            # RAG pipeline service (750+ lines) âœ…
â”‚   â”œâ”€â”€ rag_config_examples.py    # Config Ã¶rnekleri (250+ lines) âœ…
â”‚   â”œâ”€â”€ config_examples.py        # Fine-tuning configs âœ…
â”‚   â””â”€â”€ __init__.py              # Module exports âœ…
â”œâ”€â”€ test_finetune.py             # Fine-tuning tests âœ…
â”œâ”€â”€ test_vector_store.py         # Vector store tests âœ…
â”œâ”€â”€ test_rag_service.py          # RAG service tests (400+ lines) âœ…
â”œâ”€â”€ simple_test_rag.py           # Basic structure tests âœ…
â”œâ”€â”€ requirements.txt             # Dependencies âœ…
â””â”€â”€ README.md                    # Documentation âœ…
```

### ğŸ§  Core Components

#### 1. QLoRA Fine-Tuning Module (finetune.py)
- **Purpose**: Fashion domain'e Ã¶zelleÅŸtirilmiÅŸ LLM eÄŸitimi
- **Model**: Meta-Llama-3-8B-Instruct with QLoRA adapters
- **Features**:
  - 4-bit quantization ile memory optimization
  - LoRA adapters for efficient fine-tuning
  - Fashion-specific instruction dataset
  - SFTTrainer with comprehensive monitoring
  - Model merging and artifact saving

#### 2. Vector Store Builder (build_vector_store.py)
- **Purpose**: KullanÄ±cÄ± gardÄ±rop verilerini embedder ve indexler
- **Features**:
  - Sentence-Transformers embeddings
  - FAISS & Pinecone support
  - Batch processing optimization
  - Metadata management
  - Scalable vector search

#### 3. RAG Service (rag_service.py) - â­ NEW â­
- **Purpose**: Hibrit QLoRA + RAG pipeline
- **Architecture**:
  ```
  Query â†’ Embedding â†’ Vector Search â†’ Context â†’ LLM â†’ Response
     â†“         â†“           â†“            â†“       â†“        â†“
  User Q  â†’ SentTrans â†’ FAISS/Pine â†’ Format â†’ LLaMA â†’ Answer
  ```
- **Features**:
  - **RAGConfig**: Comprehensive configuration management
  - **RAGService**: Main service class
  - **Query Processing**: Natural language â†’ embeddings
  - **Context Retrieval**: Semantic search in user wardrobe
  - **Response Generation**: Fine-tuned LLM with context
  - **Batch Processing**: Multiple queries support
  - **Memory Management**: Optimized for production
  - **Error Handling**: Robust fallback mechanisms

### ğŸ”§ Configuration System

#### RAG Configuration Options:
1. **basic_rag_config()**: Development ve test iÃ§in
2. **production_rag_config()**: YÃ¼ksek performans production
3. **memory_optimized_rag_config()**: DÃ¼ÅŸÃ¼k memory sistemler
4. **fast_inference_rag_config()**: DÃ¼ÅŸÃ¼k latency prioritesi
5. **multilingual_rag_config()**: TÃ¼rkÃ§e + Ä°ngilizce support
6. **debug_rag_config()**: Development debugging

### ğŸš€ Usage Examples

#### Basic RAG Service Usage:
```python
from src.rag_service import create_rag_service

# Create service
service = create_rag_service(
    finetuned_model_path="./saved_models/aura_fashion_assistant",
    vector_store_path="./vector_stores/wardrobe_faiss.index"
)

# Generate response
response = service.generate_response(
    query="BugÃ¼n ne giysem iyi olur?",
    user_id="user123"
)

print(response["response"])
```

#### Advanced Configuration:
```python
from src.rag_service import RAGService, RAGConfig

config = RAGConfig(
    base_model_name="meta-llama/Meta-Llama-3-8B-Instruct",
    vector_store_type="pinecone",
    top_k_retrieval=8,
    temperature=0.7,
    max_new_tokens=300
)

service = RAGService(config)
```

#### Batch Processing:
```python
queries = [
    {"query": "Ä°ÅŸ toplantÄ±sÄ± iÃ§in ne giysem?", "user_id": "user1"},
    {"query": "Casual gÃ¼n iÃ§in kombinasyon Ã¶ner", "user_id": "user2"}
]

responses = service.batch_generate_responses(queries)
```

### ğŸ“Š System Capabilities

âœ… **Fine-Tuned Personality**: QLoRA ile fashion domain expertise
âœ… **Real-time Knowledge**: Vector store ile user wardrobe access
âœ… **Semantic Understanding**: Advanced embedding search
âœ… **Personalized Responses**: User-specific context retrieval
âœ… **Scalable Architecture**: FAISS/Pinecone support
âœ… **Memory Efficient**: 4-bit quantization optimizations
âœ… **Production Ready**: Comprehensive error handling
âœ… **Batch Processing**: Multiple query support
âœ… **Flexible Configuration**: Multiple use-case configs
âœ… **Comprehensive Testing**: Unit tests & integration tests

### ğŸ¯ Performance Optimizations

1. **Memory Management**:
   - 4-bit quantization for LLM
   - Efficient embedding storage
   - Context length limiting
   - Cache management

2. **Speed Optimizations**:
   - Batch embedding processing
   - Vector search optimization
   - Model inference caching
   - Parallel processing support

3. **Scalability Features**:
   - Pinecone cloud vector store
   - Distributed inference support
   - Load balancing ready
   - Horizontal scaling capable

### ğŸ§ª Testing Framework

- **test_rag_service.py**: Comprehensive test suite
  - RAGConfig testing
  - RAGService mocked testing
  - Integration testing
  - Utility function testing

- **simple_test_rag.py**: Basic structure validation
  - File creation verification
  - Import structure testing
  - Class method validation

### ğŸ”„ Integration with Other Services

#### With Visual Analysis:
- Image analysis results â†’ Context for outfit discussions
- Fashion item detection â†’ Wardrobe knowledge enhancement

#### With OutfitTransformer:
- Outfit recommendations â†’ Conversation context
- Style preferences â†’ Personalized chat responses

### ğŸŒŸ Next Steps for FastAPI Integration

1. **Chat Endpoints**: 
   - `/chat/message` - Single message processing
   - `/chat/batch` - Batch message processing
   - `/chat/history` - Conversation history

2. **User Management**:
   - User wardrobe data management
   - Preference learning
   - Context persistence

3. **Real-time Features**:
   - WebSocket chat support
   - Streaming responses
   - Live suggestions

## ğŸ‰ Summary

Hibrit QLoRA + RAG sistemi tamamen hazÄ±r! Bu sistem:

1. **Fine-tuned fashion expertise** (QLoRA)
2. **Real-time wardrobe knowledge** (Vector Store) 
3. **Intelligent conversation flow** (RAG Pipeline)
4. **Production-ready architecture** (Scalable & Optimized)

Aura platformu artÄ±k Ã¼Ã§ AI mikroservisiyle complete:
- âœ… Visual Analysis (DETR-based fashion detection)
- âœ… OutfitTransformer (Recommendation engine)  
- âœ… Conversational AI (Hibrit QLoRA + RAG chatbot)

ğŸš€ Ready for FastAPI integration and deployment!
"""

if __name__ == "__main__":
    print(__doc__)
