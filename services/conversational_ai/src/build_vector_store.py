"""
Vector Store Builder for Aura Fashion Assistant RAG System
===========================================================

Bu modÃ¼l, Aura projesinin sohbet asistanÄ± iÃ§in RAG (Retrieval-Augmented Generation) 
sisteminin vektÃ¶r veritabanÄ±nÄ± oluÅŸturur.

KullanÄ±cÄ±nÄ±n gardÄ±rop verilerini alÄ±r, sentence-transformers ile vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r
ve FAISS veya Pinecone vektÃ¶r veritabanÄ±nda saklar.

Ã–zellikler:
- Sentence Transformers ile semantic embeddings
- FAISS ve Pinecone vektÃ¶r veritabanÄ± desteÄŸi
- YapÄ±landÄ±rÄ±lmÄ±ÅŸ gardÄ±rop verisi iÅŸleme
- Visual Analysis servis entegrasyonu
- Verimli batch processing
- Metadata filtreleme desteÄŸi

Author: Aura AI Team
Version: 1.0.0
Date: 2025-08-03
"""

import os
import sys
import json
import logging
import argparse
import time
import warnings
from pathlib import Path
from typing import Dict, List, Optional, Union, Tuple, Any
import traceback
from dataclasses import dataclass, asdict
from datetime import datetime

# Core libraries
import numpy as np
import pandas as pd

# Embedding libraries
from sentence_transformers import SentenceTransformer
import torch

# Vector store libraries
import faiss
try:
    import pinecone
    PINECONE_AVAILABLE = True
except ImportError:
    PINECONE_AVAILABLE = False
    warnings.warn("Pinecone not available. Only FAISS will be supported.")

# Utility libraries
from loguru import logger
import yaml
from tqdm import tqdm
import uuid

# Configuration
warnings.filterwarnings("ignore", category=UserWarning)

# =============================================================================
# A1. MODÃœL VE KÃœTÃœPHANELERÄ° Ä°Ã‡E AKTARMA - TAMAMLANDI
# =============================================================================

# =============================================================================
# A2. KONFÄ°GÃœRASYON VE ARGÃœMANLARI TANIMLAMA
# =============================================================================

@dataclass
class VectorStoreConfig:
    """Vector store oluÅŸturma iÃ§in konfigÃ¼rasyon sÄ±nÄ±fÄ±"""
    
    # Input/Output Configuration
    input_data_path: str = "./data/user_wardrobe.json"
    output_dir: str = "./vector_stores"
    
    # Embedding Configuration
    embedding_model_name: str = "sentence-transformers/all-MiniLM-L6-v2"
    embedding_dimension: int = 384  # all-MiniLM-L6-v2 iÃ§in
    max_seq_length: int = 512
    
    # Vector Store Configuration
    vector_store_type: str = "faiss"  # "faiss" veya "pinecone"
    faiss_index_type: str = "IndexFlatIP"  # Inner Product (cosine similarity)
    
    # Pinecone Configuration (eÄŸer kullanÄ±lÄ±yorsa)
    pinecone_api_key: str = ""
    pinecone_environment: str = "us-west1-gcp-free"
    pinecone_index_name: str = "aura-wardrobe"
    pinecone_metric: str = "cosine"
    
    # Processing Configuration
    batch_size: int = 32
    normalize_embeddings: bool = True
    include_metadata: bool = True
    
    # Filtering Configuration
    min_confidence: float = 0.5  # Visual analysis minimum confidence
    supported_categories: List[str] = None
    
    def __post_init__(self):
        """Post-initialization setup"""
        if self.supported_categories is None:
            self.supported_categories = [
                "shirt", "t-shirt", "blouse", "sweater", "jacket", "coat",
                "dress", "skirt", "pants", "jeans", "shorts", 
                "shoes", "boots", "sneakers", "bag", "handbag", "accessories"
            ]


def parse_arguments() -> argparse.Namespace:
    """
    A2a. Komut satÄ±rÄ± argÃ¼manlarÄ±nÄ± tanÄ±mla ve parse et
    
    Returns:
        argparse.Namespace: Parse edilmiÅŸ argÃ¼manlar
    """
    parser = argparse.ArgumentParser(
        description="Aura Fashion Assistant - Vector Store Builder",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    
    # Input/Output arguments
    parser.add_argument(
        "--input_data_path",
        type=str,
        default="./data/user_wardrobe.json",
        help="Path to user wardrobe data (JSON file or directory)"
    )
    parser.add_argument(
        "--output_dir",
        type=str,
        default="./vector_stores",
        help="Output directory for vector store files"
    )
    
    # Embedding arguments
    parser.add_argument(
        "--embedding_model_name",
        type=str,
        default="sentence-transformers/all-MiniLM-L6-v2",
        help="Sentence transformer model name"
    )
    parser.add_argument(
        "--max_seq_length",
        type=int,
        default=512,
        help="Maximum sequence length for embeddings"
    )
    
    # Vector store arguments
    parser.add_argument(
        "--vector_store_type",
        type=str,
        choices=["faiss", "pinecone"],
        default="faiss",
        help="Type of vector store to use"
    )
    parser.add_argument(
        "--faiss_index_type",
        type=str,
        choices=["IndexFlatIP", "IndexFlatL2", "IndexIVFFlat"],
        default="IndexFlatIP",
        help="FAISS index type"
    )
    
    # Pinecone arguments
    parser.add_argument(
        "--pinecone_api_key",
        type=str,
        default="",
        help="Pinecone API key (or set PINECONE_API_KEY env var)"
    )
    parser.add_argument(
        "--pinecone_environment",
        type=str,
        default="us-west1-gcp-free",
        help="Pinecone environment"
    )
    parser.add_argument(
        "--pinecone_index_name",
        type=str,
        default="aura-wardrobe",
        help="Pinecone index name"
    )
    
    # Processing arguments
    parser.add_argument(
        "--batch_size",
        type=int,
        default=32,
        help="Batch size for embedding generation"
    )
    parser.add_argument(
        "--min_confidence",
        type=float,
        default=0.5,
        help="Minimum confidence for visual analysis results"
    )
    
    # Technical arguments
    parser.add_argument(
        "--normalize_embeddings",
        action="store_true",
        default=True,
        help="Normalize embeddings for cosine similarity"
    )
    parser.add_argument(
        "--include_metadata",
        action="store_true",
        default=True,
        help="Include metadata in vector store"
    )
    parser.add_argument(
        "--debug",
        action="store_true",
        default=False,
        help="Enable debug mode with verbose logging"
    )
    
    return parser.parse_args()


def setup_logging(debug: bool = False) -> None:
    """
    A2b. Logging sistemini yapÄ±landÄ±r
    
    Args:
        debug: Debug seviyesinde loglama aktif edilsin mi
    """
    # Remove default logger
    logger.remove()
    
    # Console logging
    log_level = "DEBUG" if debug else "INFO"
    logger.add(
        sys.stderr,
        format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>",
        level=log_level,
        colorize=True
    )
    
    # File logging
    log_file = f"vector_store_build_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
    logger.add(
        log_file,
        format="{time:YYYY-MM-DD HH:mm:ss} | {level: <8} | {name}:{function}:{line} - {message}",
        level="DEBUG",
        rotation="10 MB",
        retention="7 days"
    )
    
    logger.info("ğŸš€ Aura Vector Store Builder baÅŸlatÄ±lÄ±yor...")
    logger.info(f"ğŸ“ Log dosyasÄ±: {log_file}")


# =============================================================================
# A3. EMBEDDING MODELÄ°NÄ° YÃœKLEME
# =============================================================================

def load_embedding_model(config: VectorStoreConfig) -> SentenceTransformer:
    """
    A3a. Sentence Transformer embedding modelini yÃ¼kle
    
    Args:
        config: Vector store konfigÃ¼rasyonu
        
    Returns:
        SentenceTransformer: YÃ¼klenmiÅŸ embedding modeli
    """
    logger.info(f"ğŸ“¥ Embedding modeli yÃ¼kleniyor: {config.embedding_model_name}")
    
    try:
        # Sentence Transformer modelini yÃ¼kle
        model = SentenceTransformer(
            config.embedding_model_name,
            device='cuda' if torch.cuda.is_available() else 'cpu'
        )
        
        # Model konfigÃ¼rasyonlarÄ±nÄ± ayarla
        if hasattr(model, 'max_seq_length'):
            model.max_seq_length = config.max_seq_length
        
        logger.success(f"âœ… Embedding modeli yÃ¼klendi: {config.embedding_model_name}")
        
        # Model bilgilerini gÃ¶ster
        logger.info(f"ğŸ“Š Model bilgileri:")
        logger.info(f"  - Model name: {config.embedding_model_name}")
        logger.info(f"  - Embedding dimension: {model.get_sentence_embedding_dimension()}")
        logger.info(f"  - Max sequence length: {getattr(model, 'max_seq_length', 'N/A')}")
        logger.info(f"  - Device: {model.device}")
        
        # Embedding dimension'Ä± config'e kaydet
        config.embedding_dimension = model.get_sentence_embedding_dimension()
        
        return model
        
    except Exception as e:
        logger.error(f"âŒ Embedding modeli yÃ¼kleme hatasÄ±: {str(e)}")
        logger.error(f"Traceback: {traceback.format_exc()}")
        raise


# =============================================================================
# A4. KULLANICI GARDIROBÄ± VERISINI YÃœKLEME
# =============================================================================

def load_wardrobe_data(config: VectorStoreConfig) -> List[Dict[str, Any]]:
    """
    A4a. KullanÄ±cÄ± gardÄ±rop verisini yÃ¼kle ve iÅŸle
    
    Args:
        config: Vector store konfigÃ¼rasyonu
        
    Returns:
        List[Dict[str, Any]]: Ä°ÅŸlenmiÅŸ gardÄ±rop verisi
    """
    logger.info(f"ğŸ“Š GardÄ±rop verisi yÃ¼kleniyor: {config.input_data_path}")
    
    try:
        input_path = Path(config.input_data_path)
        
        if not input_path.exists():
            # Ã–rnek veri oluÅŸtur
            logger.warning(f"âš ï¸ Veri dosyasÄ± bulunamadÄ±: {input_path}")
            logger.info("ğŸ“ Ã–rnek gardÄ±rop verisi oluÅŸturuluyor...")
            
            sample_data = create_sample_wardrobe_data()
            
            # Ã–rnek veriyi kaydet
            input_path.parent.mkdir(parents=True, exist_ok=True)
            with open(input_path, 'w', encoding='utf-8') as f:
                json.dump(sample_data, f, indent=2, ensure_ascii=False)
            
            logger.success(f"âœ… Ã–rnek veri oluÅŸturuldu: {input_path}")
            return sample_data
        
        # DosyayÄ± yÃ¼kle
        if input_path.is_file():
            # Tek dosya
            if input_path.suffix.lower() == '.json':
                with open(input_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
            else:
                raise ValueError(f"Desteklenmeyen dosya formatÄ±: {input_path.suffix}")
                
        elif input_path.is_dir():
            # Dizindeki tÃ¼m JSON dosyalarÄ±nÄ± yÃ¼kle
            data = []
            json_files = list(input_path.glob("*.json"))
            
            if not json_files:
                raise FileNotFoundError(f"Dizinde JSON dosyasÄ± bulunamadÄ±: {input_path}")
            
            for json_file in json_files:
                logger.info(f"  ğŸ“ YÃ¼kleniyor: {json_file.name}")
                with open(json_file, 'r', encoding='utf-8') as f:
                    file_data = json.load(f)
                    if isinstance(file_data, list):
                        data.extend(file_data)
                    else:
                        data.append(file_data)
        
        logger.info(f"ğŸ“Š Ham veri boyutu: {len(data)} item")
        
        # Veriyi iÅŸle ve filtrele
        processed_data = process_wardrobe_data(data, config)
        
        logger.success(f"âœ… GardÄ±rop verisi yÃ¼klendi: {len(processed_data)} iÅŸlenmiÅŸ item")
        
        return processed_data
        
    except Exception as e:
        logger.error(f"âŒ Veri yÃ¼kleme hatasÄ±: {str(e)}")
        logger.error(f"Traceback: {traceback.format_exc()}")
        raise


def create_sample_wardrobe_data() -> List[Dict[str, Any]]:
    """
    A4b. Ã–rnek gardÄ±rop verisi oluÅŸtur (Visual Analysis formatÄ±nda)
    
    Returns:
        List[Dict[str, Any]]: Ã–rnek gardÄ±rop verisi
    """
    sample_items = [
        {
            "id": str(uuid.uuid4()),
            "user_id": "user_123",
            "image_path": "/images/blue_jeans.jpg",
            "visual_analysis": {
                "detections": [
                    {
                        "label": "jeans",
                        "confidence": 0.95,
                        "bbox": [10, 20, 200, 400],
                        "attributes": {
                            "colors": ["blue", "denim"],
                            "patterns": ["solid"],
                            "styles": ["casual", "straight-leg"],
                            "materials": ["denim", "cotton"]
                        }
                    }
                ],
                "summary": {
                    "total_detections": 1,
                    "categories_found": ["jeans"]
                }
            },
            "user_tags": ["casual", "everyday", "comfortable"],
            "brand": "Levi's",
            "size": "M",
            "color_primary": "blue",
            "season": ["spring", "fall", "winter"],
            "occasion": ["casual", "work"],
            "purchase_date": "2024-01-15",
            "last_worn": "2024-07-20"
        },
        {
            "id": str(uuid.uuid4()),
            "user_id": "user_123",
            "image_path": "/images/white_shirt.jpg",
            "visual_analysis": {
                "detections": [
                    {
                        "label": "shirt",
                        "confidence": 0.92,
                        "bbox": [15, 10, 180, 250],
                        "attributes": {
                            "colors": ["white"],
                            "patterns": ["solid"],
                            "styles": ["business", "button-down"],
                            "materials": ["cotton", "polyester"]
                        }
                    }
                ],
                "summary": {
                    "total_detections": 1,
                    "categories_found": ["shirt"]
                }
            },
            "user_tags": ["business", "formal", "versatile"],
            "brand": "Brooks Brothers",
            "size": "L",
            "color_primary": "white",
            "season": ["spring", "summer", "fall"],
            "occasion": ["business", "formal", "date"],
            "purchase_date": "2024-02-10",
            "last_worn": "2024-07-25"
        },
        {
            "id": str(uuid.uuid4()),
            "user_id": "user_123",
            "image_path": "/images/black_dress.jpg",
            "visual_analysis": {
                "detections": [
                    {
                        "label": "dress",
                        "confidence": 0.98,
                        "bbox": [5, 5, 190, 380],
                        "attributes": {
                            "colors": ["black"],
                            "patterns": ["solid"],
                            "styles": ["cocktail", "sleeveless"],
                            "materials": ["polyester", "spandex"]
                        }
                    }
                ],
                "summary": {
                    "total_detections": 1,
                    "categories_found": ["dress"]
                }
            },
            "user_tags": ["elegant", "special occasions", "favorite"],
            "brand": "Zara",
            "size": "S",
            "color_primary": "black",
            "season": ["summer", "spring"],
            "occasion": ["formal", "party", "date"],
            "purchase_date": "2024-03-20",
            "last_worn": "2024-07-15"
        },
        {
            "id": str(uuid.uuid4()),
            "user_id": "user_123",
            "image_path": "/images/sneakers.jpg",
            "visual_analysis": {
                "detections": [
                    {
                        "label": "sneakers",
                        "confidence": 0.89,
                        "bbox": [20, 50, 160, 120],
                        "attributes": {
                            "colors": ["white", "black"],
                            "patterns": ["solid", "logo"],
                            "styles": ["athletic", "casual"],
                            "materials": ["leather", "rubber"]
                        }
                    }
                ],
                "summary": {
                    "total_detections": 1,
                    "categories_found": ["sneakers"]
                }
            },
            "user_tags": ["comfortable", "sporty", "everyday"],
            "brand": "Nike",
            "size": "9",
            "color_primary": "white",
            "season": ["spring", "summer", "fall"],
            "occasion": ["casual", "sport", "travel"],
            "purchase_date": "2024-01-05",
            "last_worn": "2024-07-30"
        },
        {
            "id": str(uuid.uuid4()),
            "user_id": "user_123",
            "image_path": "/images/blazer.jpg",
            "visual_analysis": {
                "detections": [
                    {
                        "label": "jacket",
                        "confidence": 0.94,
                        "bbox": [8, 12, 185, 280],
                        "attributes": {
                            "colors": ["navy", "blue"],
                            "patterns": ["solid"],
                            "styles": ["blazer", "tailored"],
                            "materials": ["wool", "polyester"]
                        }
                    }
                ],
                "summary": {
                    "total_detections": 1,
                    "categories_found": ["jacket"]
                }
            },
            "user_tags": ["professional", "versatile", "investment piece"],
            "brand": "Hugo Boss",
            "size": "M",
            "color_primary": "navy",
            "season": ["fall", "winter", "spring"],
            "occasion": ["business", "formal", "smart casual"],
            "purchase_date": "2024-04-12",
            "last_worn": "2024-07-28"
        }
    ]
    
    return sample_items


def process_wardrobe_data(data: List[Dict[str, Any]], config: VectorStoreConfig) -> List[Dict[str, Any]]:
    """
    A4c. Ham gardÄ±rop verisini iÅŸle ve filtrele
    
    Args:
        data: Ham gardÄ±rop verisi
        config: Vector store konfigÃ¼rasyonu
        
    Returns:
        List[Dict[str, Any]]: Ä°ÅŸlenmiÅŸ ve filtrelenmiÅŸ veri
    """
    logger.info("ğŸ§¹ GardÄ±rop verisi iÅŸleniyor...")
    
    processed_items = []
    
    for item in data:
        try:
            # ID kontrolÃ¼
            if 'id' not in item:
                item['id'] = str(uuid.uuid4())
            
            # Visual analysis kontrolÃ¼
            if 'visual_analysis' not in item or not item['visual_analysis']:
                logger.warning(f"âš ï¸ Visual analysis verisi eksik: {item.get('id', 'unknown')}")
                continue
            
            detections = item['visual_analysis'].get('detections', [])
            if not detections:
                logger.warning(f"âš ï¸ Detection verisi eksik: {item.get('id', 'unknown')}")
                continue
            
            # Confidence filtreleme
            valid_detections = [
                det for det in detections 
                if det.get('confidence', 0) >= config.min_confidence
            ]
            
            if not valid_detections:
                logger.debug(f"âš ï¸ DÃ¼ÅŸÃ¼k confidence, filtrelendi: {item.get('id', 'unknown')}")
                continue
            
            # Kategori filtreleme
            item_categories = [det.get('label', '').lower() for det in valid_detections]
            supported_found = any(
                cat in config.supported_categories 
                for cat in item_categories
            )
            
            if not supported_found:
                logger.debug(f"âš ï¸ Desteklenmeyen kategori, filtrelendi: {item.get('id', 'unknown')}")
                continue
            
            # Veriyi zenginleÅŸtir
            item['processed_detections'] = valid_detections
            item['processed_categories'] = item_categories
            
            processed_items.append(item)
            
        except Exception as e:
            logger.warning(f"âš ï¸ Item iÅŸleme hatasÄ±: {str(e)} - {item.get('id', 'unknown')}")
            continue
    
    logger.info(f"ğŸ§¹ Veri iÅŸleme tamamlandÄ±:")
    logger.info(f"  - Ham itemlar: {len(data)}")
    logger.info(f"  - Ä°ÅŸlenmiÅŸ itemlar: {len(processed_items)}")
    logger.info(f"  - Filtrelenen itemlar: {len(data) - len(processed_items)}")
    
    return processed_items


# =============================================================================
# A5. VEKTÃ–R VERÄ°TABANINI (FAISS VEYA PINECONE) BAÅLATMA
# =============================================================================

def initialize_vector_store(config: VectorStoreConfig) -> Union[faiss.Index, Any]:
    """
    A5a. Vector store'u baÅŸlat (FAISS veya Pinecone)
    
    Args:
        config: Vector store konfigÃ¼rasyonu
        
    Returns:
        Union[faiss.Index, Any]: Ä°nitialize edilmiÅŸ vector store
    """
    logger.info(f"ğŸ”§ Vector store baÅŸlatÄ±lÄ±yor: {config.vector_store_type}")
    
    if config.vector_store_type == "faiss":
        return initialize_faiss_store(config)
    elif config.vector_store_type == "pinecone":
        return initialize_pinecone_store(config)
    else:
        raise ValueError(f"Desteklenmeyen vector store tipi: {config.vector_store_type}")


def initialize_faiss_store(config: VectorStoreConfig) -> faiss.Index:
    """
    A5b. FAISS vector store'unu baÅŸlat
    
    Args:
        config: Vector store konfigÃ¼rasyonu
        
    Returns:
        faiss.Index: FAISS indeksi
    """
    logger.info("ğŸ”§ FAISS vector store baÅŸlatÄ±lÄ±yor...")
    
    try:
        # FAISS indeks tipine gÃ¶re indeks oluÅŸtur
        if config.faiss_index_type == "IndexFlatIP":
            # Inner Product (cosine similarity iÃ§in normalize gerekli)
            base_index = faiss.IndexFlatIP(config.embedding_dimension)
        elif config.faiss_index_type == "IndexFlatL2":
            # L2 distance
            base_index = faiss.IndexFlatL2(config.embedding_dimension)
        elif config.faiss_index_type == "IndexIVFFlat":
            # IVF (daha bÃ¼yÃ¼k veri setleri iÃ§in)
            quantizer = faiss.IndexFlatL2(config.embedding_dimension)
            base_index = faiss.IndexIVFFlat(quantizer, config.embedding_dimension, 100)
        else:
            raise ValueError(f"Desteklenmeyen FAISS indeks tipi: {config.faiss_index_type}")
        
        # ID mapping iÃ§in IndexIDMap kullan
        index = faiss.IndexIDMap(base_index)
        
        logger.success(f"âœ… FAISS indeksi oluÅŸturuldu:")
        logger.info(f"  - Index type: {config.faiss_index_type}")
        logger.info(f"  - Dimension: {config.embedding_dimension}")
        logger.info(f"  - Is trained: {index.is_trained}")
        
        return index
        
    except Exception as e:
        logger.error(f"âŒ FAISS indeks oluÅŸturma hatasÄ±: {str(e)}")
        logger.error(f"Traceback: {traceback.format_exc()}")
        raise


def initialize_pinecone_store(config: VectorStoreConfig) -> Any:
    """
    A5c. Pinecone vector store'unu baÅŸlat
    
    Args:
        config: Vector store konfigÃ¼rasyonu
        
    Returns:
        Any: Pinecone indeksi
    """
    if not PINECONE_AVAILABLE:
        raise ImportError("Pinecone paketi kurulu deÄŸil. pip install pinecone-client komutu ile kurun.")
    
    logger.info("ğŸ”§ Pinecone vector store baÅŸlatÄ±lÄ±yor...")
    
    try:
        # API key'i al
        api_key = config.pinecone_api_key or os.getenv("PINECONE_API_KEY")
        if not api_key:
            raise ValueError("Pinecone API key bulunamadÄ±. --pinecone_api_key argÃ¼manÄ± veya PINECONE_API_KEY environment variable ayarlayÄ±n.")
        
        # Pinecone'u baÅŸlat
        pinecone.init(
            api_key=api_key,
            environment=config.pinecone_environment
        )
        
        # Ä°ndeks listesini kontrol et
        existing_indexes = pinecone.list_indexes()
        
        if config.pinecone_index_name not in existing_indexes:
            # Yeni indeks oluÅŸtur
            logger.info(f"ğŸ”§ Pinecone indeksi oluÅŸturuluyor: {config.pinecone_index_name}")
            
            pinecone.create_index(
                name=config.pinecone_index_name,
                dimension=config.embedding_dimension,
                metric=config.pinecone_metric
            )
            
            # Ä°ndeksin hazÄ±r olmasÄ±nÄ± bekle
            import time
            time.sleep(10)
            
            logger.success(f"âœ… Pinecone indeksi oluÅŸturuldu: {config.pinecone_index_name}")
        else:
            logger.info(f"ğŸ“‚ Mevcut Pinecone indeksi kullanÄ±lÄ±yor: {config.pinecone_index_name}")
        
        # Ä°ndekse baÄŸlan
        index = pinecone.Index(config.pinecone_index_name)
        
        # Ä°ndeks bilgilerini gÃ¶ster
        stats = index.describe_index_stats()
        logger.info(f"ğŸ“Š Pinecone indeks bilgileri:")
        logger.info(f"  - Index name: {config.pinecone_index_name}")
        logger.info(f"  - Dimension: {config.embedding_dimension}")
        logger.info(f"  - Metric: {config.pinecone_metric}")
        logger.info(f"  - Total vectors: {stats.get('total_vector_count', 0)}")
        
        return index
        
    except Exception as e:
        logger.error(f"âŒ Pinecone indeks oluÅŸturma hatasÄ±: {str(e)}")
        logger.error(f"Traceback: {traceback.format_exc()}")
        raise


# =============================================================================
# A6. VERÄ°LERÄ° EMBEDDING'LEME VE VERÄ°TABANINA EKLEME
# =============================================================================

def generate_embeddings_and_add_to_store(
    items: List[Dict[str, Any]],
    embedding_model: SentenceTransformer,
    vector_store: Union[faiss.Index, Any],
    config: VectorStoreConfig
) -> None:
    """
    A6a. GardÄ±rop itemlarÄ±nÄ± embedding'le ve vector store'a ekle
    
    Args:
        items: Ä°ÅŸlenmiÅŸ gardÄ±rop itemlarÄ±
        embedding_model: Sentence transformer modeli
        vector_store: Vector store (FAISS veya Pinecone)
        config: Vector store konfigÃ¼rasyonu
    """
    logger.info(f"ğŸ”„ {len(items)} item iÃ§in embedding'ler oluÅŸturuluyor...")
    
    try:
        # Metinleri hazÄ±rla
        texts = []
        ids = []
        metadata_list = []
        
        for item in items:
            # Item iÃ§in aÃ§Ä±klayÄ±cÄ± metin oluÅŸtur
            description = create_item_description(item)
            texts.append(description)
            ids.append(item['id'])
            
            # Metadata hazÄ±rla
            if config.include_metadata:
                metadata = create_item_metadata(item)
                metadata_list.append(metadata)
        
        logger.info(f"ğŸ“ {len(texts)} metin aÃ§Ä±klamasÄ± hazÄ±rlandÄ±")
        
        # Batch'ler halinde embedding'leri oluÅŸtur
        all_embeddings = []
        
        for i in tqdm(range(0, len(texts), config.batch_size), desc="Embedding generation"):
            batch_texts = texts[i:i + config.batch_size]
            
            # Embeddings oluÅŸtur
            batch_embeddings = embedding_model.encode(
                batch_texts,
                convert_to_numpy=True,
                normalize_embeddings=config.normalize_embeddings,
                show_progress_bar=False
            )
            
            all_embeddings.append(batch_embeddings)
        
        # TÃ¼m embedding'leri birleÅŸtir
        embeddings = np.vstack(all_embeddings)
        logger.success(f"âœ… Embeddings oluÅŸturuldu: {embeddings.shape}")
        
        # Vector store'a ekle
        if config.vector_store_type == "faiss":
            add_to_faiss_store(vector_store, embeddings, ids, metadata_list, config)
        elif config.vector_store_type == "pinecone":
            add_to_pinecone_store(vector_store, embeddings, ids, metadata_list, config)
        
        logger.success(f"âœ… {len(items)} item vector store'a eklendi")
        
    except Exception as e:
        logger.error(f"âŒ Embedding ve ekleme hatasÄ±: {str(e)}")
        logger.error(f"Traceback: {traceback.format_exc()}")
        raise


def create_item_description(item: Dict[str, Any]) -> str:
    """
    A6b. GardÄ±rop item'Ä± iÃ§in aÃ§Ä±klayÄ±cÄ± metin oluÅŸtur
    
    Args:
        item: GardÄ±rop item'Ä±
        
    Returns:
        str: AÃ§Ä±klayÄ±cÄ± metin
    """
    description_parts = []
    
    # Visual analysis detaylarÄ±
    detections = item.get('processed_detections', [])
    for detection in detections:
        label = detection.get('label', '')
        attributes = detection.get('attributes', {})
        
        # Temel item aÃ§Ä±klamasÄ±
        if label:
            description_parts.append(f"This is a {label}")
        
        # Renk bilgisi
        colors = attributes.get('colors', [])
        if colors:
            color_text = ", ".join(colors)
            description_parts.append(f"in {color_text} color")
        
        # Stil bilgisi
        styles = attributes.get('styles', [])
        if styles:
            style_text = ", ".join(styles)
            description_parts.append(f"with {style_text} style")
        
        # Malzeme bilgisi
        materials = attributes.get('materials', [])
        if materials:
            material_text = ", ".join(materials)
            description_parts.append(f"made of {material_text}")
        
        # Desen bilgisi
        patterns = attributes.get('patterns', [])
        if patterns and patterns != ['solid']:
            pattern_text = ", ".join(patterns)
            description_parts.append(f"featuring {pattern_text} pattern")
    
    # KullanÄ±cÄ± etiketleri
    user_tags = item.get('user_tags', [])
    if user_tags:
        tags_text = ", ".join(user_tags)
        description_parts.append(f"Described as {tags_text}")
    
    # Marka bilgisi
    brand = item.get('brand')
    if brand:
        description_parts.append(f"Brand: {brand}")
    
    # Mevsim bilgisi
    seasons = item.get('season', [])
    if seasons:
        season_text = ", ".join(seasons)
        description_parts.append(f"Suitable for {season_text}")
    
    # Etkinlik bilgisi
    occasions = item.get('occasion', [])
    if occasions:
        occasion_text = ", ".join(occasions)
        description_parts.append(f"Perfect for {occasion_text} occasions")
    
    # Metni birleÅŸtir
    description = ". ".join(description_parts) + "."
    
    return description


def create_item_metadata(item: Dict[str, Any]) -> Dict[str, Any]:
    """
    A6c. Item iÃ§in metadata oluÅŸtur
    
    Args:
        item: GardÄ±rop item'Ä±
        
    Returns:
        Dict[str, Any]: Metadata
    """
    metadata = {
        "id": item.get('id'),
        "user_id": item.get('user_id'),
        "image_path": item.get('image_path'),
        "brand": item.get('brand'),
        "size": item.get('size'),
        "color_primary": item.get('color_primary'),
        "purchase_date": item.get('purchase_date'),
        "last_worn": item.get('last_worn'),
    }
    
    # Kategoriler
    categories = item.get('processed_categories', [])
    if categories:
        metadata['categories'] = categories
    
    # KullanÄ±cÄ± etiketleri
    user_tags = item.get('user_tags', [])
    if user_tags:
        metadata['user_tags'] = user_tags
    
    # Mevsim ve etkinlik
    seasons = item.get('season', [])
    if seasons:
        metadata['seasons'] = seasons
    
    occasions = item.get('occasion', [])
    if occasions:
        metadata['occasions'] = occasions
    
    # Visual analysis Ã¶zeti
    if 'visual_analysis' in item:
        va_summary = item['visual_analysis'].get('summary', {})
        metadata['total_detections'] = va_summary.get('total_detections', 0)
        metadata['categories_found'] = va_summary.get('categories_found', [])
    
    # None deÄŸerleri temizle
    metadata = {k: v for k, v in metadata.items() if v is not None}
    
    return metadata


def add_to_faiss_store(
    index: faiss.Index,
    embeddings: np.ndarray,
    ids: List[str],
    metadata_list: List[Dict[str, Any]],
    config: VectorStoreConfig
) -> None:
    """
    A6d. FAISS store'a embedding'leri ekle
    
    Args:
        index: FAISS indeksi
        embeddings: Embedding vektÃ¶rleri
        ids: Item ID'leri
        metadata_list: Metadata listesi
        config: Vector store konfigÃ¼rasyonu
    """
    logger.info("ğŸ’¾ FAISS store'a vektÃ¶rler ekleniyor...")
    
    try:
        # ID'leri integer'a dÃ¶nÃ¼ÅŸtÃ¼r (FAISS requirement)
        # UUID'leri hash'le
        int_ids = np.array([hash(id_str) % (2**63 - 1) for id_str in ids], dtype=np.int64)
        
        # VektÃ¶rleri ekle
        index.add_with_ids(embeddings.astype(np.float32), int_ids)
        
        logger.success(f"âœ… FAISS'e {len(embeddings)} vektÃ¶r eklendi")
        logger.info(f"ğŸ“Š FAISS indeks bilgileri:")
        logger.info(f"  - Total vectors: {index.ntotal}")
        logger.info(f"  - Is trained: {index.is_trained}")
        
    except Exception as e:
        logger.error(f"âŒ FAISS'e ekleme hatasÄ±: {str(e)}")
        raise


def add_to_pinecone_store(
    index: Any,
    embeddings: np.ndarray,
    ids: List[str],
    metadata_list: List[Dict[str, Any]],
    config: VectorStoreConfig
) -> None:
    """
    A6e. Pinecone store'a embedding'leri ekle
    
    Args:
        index: Pinecone indeksi
        embeddings: Embedding vektÃ¶rleri
        ids: Item ID'leri
        metadata_list: Metadata listesi
        config: Vector store konfigÃ¼rasyonu
    """
    logger.info("ğŸ’¾ Pinecone store'a vektÃ¶rler ekleniyor...")
    
    try:
        # Pinecone format'Ä±na dÃ¶nÃ¼ÅŸtÃ¼r
        vectors_to_upsert = []
        
        for i, (id_str, embedding) in enumerate(zip(ids, embeddings)):
            vector_data = {
                "id": id_str,
                "values": embedding.tolist()
            }
            
            # Metadata ekle
            if config.include_metadata and i < len(metadata_list):
                # Pinecone metadata constraints'leri dikkate al
                metadata = {}
                for key, value in metadata_list[i].items():
                    if isinstance(value, (str, int, float, bool)):
                        metadata[key] = value
                    elif isinstance(value, list):
                        # List'leri string'e dÃ¶nÃ¼ÅŸtÃ¼r
                        metadata[key] = ", ".join(map(str, value))
                
                vector_data["metadata"] = metadata
            
            vectors_to_upsert.append(vector_data)
        
        # Batch'ler halinde upsert
        batch_size = 100  # Pinecone limit
        
        for i in tqdm(range(0, len(vectors_to_upsert), batch_size), desc="Pinecone upsert"):
            batch = vectors_to_upsert[i:i + batch_size]
            index.upsert(vectors=batch)
        
        logger.success(f"âœ… Pinecone'e {len(embeddings)} vektÃ¶r eklendi")
        
        # Ä°ndeks istatistikleri
        stats = index.describe_index_stats()
        logger.info(f"ğŸ“Š Pinecone indeks bilgileri:")
        logger.info(f"  - Total vectors: {stats.get('total_vector_count', 0)}")
        
    except Exception as e:
        logger.error(f"âŒ Pinecone'e ekleme hatasÄ±: {str(e)}")
        raise


# =============================================================================
# A7. VEKTÃ–R VERÄ°TABANINI KAYDETME
# =============================================================================

def save_vector_store(
    vector_store: Union[faiss.Index, Any],
    config: VectorStoreConfig,
    metadata: Dict[str, Any]
) -> None:
    """
    A7a. Vector store'u kaydet
    
    Args:
        vector_store: Vector store (FAISS veya Pinecone)
        config: Vector store konfigÃ¼rasyonu
        metadata: Kaydedilecek metadata
    """
    logger.info("ğŸ’¾ Vector store kaydediliyor...")
    
    if config.vector_store_type == "faiss":
        save_faiss_store(vector_store, config, metadata)
    elif config.vector_store_type == "pinecone":
        save_pinecone_config(config, metadata)
    
    logger.success("âœ… Vector store baÅŸarÄ±yla kaydedildi")


def save_faiss_store(
    index: faiss.Index,
    config: VectorStoreConfig,
    metadata: Dict[str, Any]
) -> None:
    """
    A7b. FAISS store'u dosyaya kaydet
    
    Args:
        index: FAISS indeksi
        config: Vector store konfigÃ¼rasyonu
        metadata: Kaydedilecek metadata
    """
    try:
        # Output directory oluÅŸtur
        output_dir = Path(config.output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # FAISS indeksini kaydet
        index_path = output_dir / "faiss_index.index"
        faiss.write_index(index, str(index_path))
        
        logger.success(f"âœ… FAISS indeksi kaydedildi: {index_path}")
        
        # Metadata'yÄ± kaydet
        metadata_path = output_dir / "metadata.json"
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False, default=str)
        
        logger.success(f"âœ… Metadata kaydedildi: {metadata_path}")
        
        # Configuration'Ä± kaydet
        config_path = output_dir / "vector_store_config.json"
        config_dict = asdict(config)
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(config_dict, f, indent=2, ensure_ascii=False, default=str)
        
        logger.success(f"âœ… Configuration kaydedildi: {config_path}")
        
        # KullanÄ±m kÄ±lavuzu oluÅŸtur
        readme_path = output_dir / "README.md"
        create_usage_guide(readme_path, config, metadata)
        
        logger.info(f"ğŸ“ Vector store dosyalarÄ±:")
        for file_path in output_dir.iterdir():
            if file_path.is_file():
                file_size = file_path.stat().st_size / 1024**2  # MB
                logger.info(f"  - {file_path.name}: {file_size:.2f} MB")
        
    except Exception as e:
        logger.error(f"âŒ FAISS kaydetme hatasÄ±: {str(e)}")
        raise


def save_pinecone_config(config: VectorStoreConfig, metadata: Dict[str, Any]) -> None:
    """
    A7c. Pinecone konfigÃ¼rasyonunu kaydet
    
    Args:
        config: Vector store konfigÃ¼rasyonu
        metadata: Kaydedilecek metadata
    """
    try:
        # Output directory oluÅŸtur
        output_dir = Path(config.output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # Pinecone connection info
        pinecone_info = {
            "index_name": config.pinecone_index_name,
            "environment": config.pinecone_environment,
            "metric": config.pinecone_metric,
            "dimension": config.embedding_dimension,
            "created_at": datetime.now().isoformat()
        }
        
        pinecone_path = output_dir / "pinecone_config.json"
        with open(pinecone_path, 'w', encoding='utf-8') as f:
            json.dump(pinecone_info, f, indent=2, ensure_ascii=False)
        
        logger.success(f"âœ… Pinecone config kaydedildi: {pinecone_path}")
        
        # Metadata'yÄ± kaydet
        metadata_path = output_dir / "metadata.json"
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False, default=str)
        
        logger.success(f"âœ… Metadata kaydedildi: {metadata_path}")
        
        # KullanÄ±m kÄ±lavuzu oluÅŸtur
        readme_path = output_dir / "README.md"
        create_usage_guide(readme_path, config, metadata)
        
    except Exception as e:
        logger.error(f"âŒ Pinecone config kaydetme hatasÄ±: {str(e)}")
        raise


def create_usage_guide(readme_path: Path, config: VectorStoreConfig, metadata: Dict[str, Any]) -> None:
    """
    A7d. Vector store kullanÄ±m kÄ±lavuzu oluÅŸtur
    
    Args:
        readme_path: README dosya yolu
        config: Vector store konfigÃ¼rasyonu
        metadata: Vector store metadata'sÄ±
    """
    guide_content = f"""# Aura Fashion Assistant - Vector Store

Bu vector store, Aura moda asistanÄ±nÄ±n RAG sistemi iÃ§in oluÅŸturulmuÅŸtur.

## Vector Store Bilgileri

- **Type**: {config.vector_store_type}
- **Embedding Model**: {config.embedding_model_name}
- **Dimension**: {config.embedding_dimension}
- **Created**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **Total Items**: {metadata.get('total_items', 'N/A')}

## Dosyalar

### FAISS Store (eÄŸer kullanÄ±lÄ±yorsa)
- `faiss_index.index`: FAISS indeks dosyasÄ±
- `metadata.json`: Item metadata'larÄ±
- `vector_store_config.json`: Vector store konfigÃ¼rasyonu

### Pinecone Store (eÄŸer kullanÄ±lÄ±yorsa)
- `pinecone_config.json`: Pinecone baÄŸlantÄ± bilgileri
- `metadata.json`: Item metadata'larÄ±

## KullanÄ±m

### FAISS Store YÃ¼kleme

```python
import faiss
import json

# Ä°ndeksi yÃ¼kle
index = faiss.read_index("faiss_index.index")

# Metadata'yÄ± yÃ¼kle
with open("metadata.json", "r") as f:
    metadata = json.load(f)

# Arama yap
query_vector = ...  # Embedding vektÃ¶rÃ¼
k = 5  # DÃ¶ndÃ¼rÃ¼lecek sonuÃ§ sayÄ±sÄ±
distances, indices = index.search(query_vector, k)
```

### Pinecone Store Kullanma

```python
import pinecone
import json

# Config'i yÃ¼kle
with open("pinecone_config.json", "r") as f:
    config = json.load(f)

# Pinecone'a baÄŸlan
pinecone.init(api_key="your-api-key", environment=config["environment"])
index = pinecone.Index(config["index_name"])

# Arama yap
query_vector = ...  # Embedding vektÃ¶rÃ¼
results = index.query(vector=query_vector, top_k=5, include_metadata=True)
```

## Metadata YapÄ±sÄ±

Her gardÄ±rop item'Ä± iÃ§in aÅŸaÄŸÄ±daki metadata saklanÄ±r:

```json
{{
    "id": "unique-item-id",
    "user_id": "user-123",
    "categories": ["shirt", "casual"],
    "brand": "Brand Name",
    "color_primary": "blue",
    "seasons": ["spring", "fall"],
    "occasions": ["casual", "work"],
    "user_tags": ["favorite", "comfortable"]
}}
```

## Yeniden OluÅŸturma

Vector store'u yeniden oluÅŸturmak iÃ§in:

```bash
python src/build_vector_store.py \\
    --input_data_path ./data/user_wardrobe.json \\
    --vector_store_type {config.vector_store_type} \\
    --embedding_model_name {config.embedding_model_name} \\
    --output_dir {config.output_dir}
```

---
Generated by Aura Vector Store Builder v1.0.0
"""
    
    with open(readme_path, 'w', encoding='utf-8') as f:
        f.write(guide_content)
    
    logger.success(f"âœ… KullanÄ±m kÄ±lavuzu oluÅŸturuldu: {readme_path}")


# =============================================================================
# MAIN FUNCTION VE SCRIPT RUNNER
# =============================================================================

def main():
    """
    Ana vector store oluÅŸturma pipeline'Ä±
    
    Bu fonksiyon tÃ¼m adÄ±mlarÄ± sÄ±rasÄ±yla Ã§alÄ±ÅŸtÄ±rÄ±r:
    1. Arguments parsing ve configuration
    2. Embedding modeli yÃ¼kleme
    3. GardÄ±rop verisini yÃ¼kleme
    4. Vector store baÅŸlatma
    5. Embedding'leme ve ekleme
    6. Kaydetme
    """
    try:
        # A2. ArgÃ¼manlarÄ± parse et ve configuration oluÅŸtur
        args = parse_arguments()
        setup_logging(debug=args.debug)
        
        logger.info("ğŸ¯ Aura Fashion Assistant Vector Store Builder")
        logger.info("=" * 60)
        
        # Configuration objesi oluÅŸtur
        config = VectorStoreConfig(
            input_data_path=args.input_data_path,
            output_dir=args.output_dir,
            embedding_model_name=args.embedding_model_name,
            max_seq_length=args.max_seq_length,
            vector_store_type=args.vector_store_type,
            faiss_index_type=args.faiss_index_type,
            pinecone_api_key=args.pinecone_api_key,
            pinecone_environment=args.pinecone_environment,
            pinecone_index_name=args.pinecone_index_name,
            batch_size=args.batch_size,
            min_confidence=args.min_confidence,
            normalize_embeddings=args.normalize_embeddings,
            include_metadata=args.include_metadata,
        )
        
        logger.info("ğŸ“‹ Configuration:")
        logger.info(f"  - Input data: {config.input_data_path}")
        logger.info(f"  - Output dir: {config.output_dir}")
        logger.info(f"  - Embedding model: {config.embedding_model_name}")
        logger.info(f"  - Vector store: {config.vector_store_type}")
        logger.info(f"  - Batch size: {config.batch_size}")
        
        # System info
        logger.info("ğŸ–¥ï¸ System Information:")
        logger.info(f"  - PyTorch version: {torch.__version__}")
        logger.info(f"  - CUDA available: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            logger.info(f"  - GPU name: {torch.cuda.get_device_name(0)}")
        
        # A3. Embedding modeli yÃ¼kleme
        logger.info("\n" + "="*60)
        logger.info("ADIM 1: EMBEDDING MODELÄ° YÃœKLEME")
        logger.info("="*60)
        
        embedding_model = load_embedding_model(config)
        
        # A4. GardÄ±rop verisini yÃ¼kleme
        logger.info("\n" + "="*60)
        logger.info("ADIM 2: GARDÄ±ROP VERISINÄ° YÃœKLEME")
        logger.info("="*60)
        
        wardrobe_items = load_wardrobe_data(config)
        
        if not wardrobe_items:
            logger.error("âŒ Ä°ÅŸlenecek gardÄ±rop verisi bulunamadÄ±")
            return
        
        # A5. Vector store baÅŸlatma
        logger.info("\n" + "="*60)
        logger.info("ADIM 3: VECTOR STORE BAÅLATMA")
        logger.info("="*60)
        
        vector_store = initialize_vector_store(config)
        
        # A6. Embedding'leme ve ekleme
        logger.info("\n" + "="*60)
        logger.info("ADIM 4: EMBEDDING'LEME VE EKLEME")
        logger.info("="*60)
        
        generate_embeddings_and_add_to_store(
            wardrobe_items,
            embedding_model,
            vector_store,
            config
        )
        
        # A7. Kaydetme
        logger.info("\n" + "="*60)
        logger.info("ADIM 5: VECTOR STORE KAYDETME")
        logger.info("="*60)
        
        # Metadata oluÅŸtur
        metadata = {
            "created_at": datetime.now().isoformat(),
            "total_items": len(wardrobe_items),
            "embedding_model": config.embedding_model_name,
            "embedding_dimension": config.embedding_dimension,
            "vector_store_type": config.vector_store_type,
            "min_confidence": config.min_confidence,
            "categories_processed": list(set(
                cat for item in wardrobe_items 
                for cat in item.get('processed_categories', [])
            )),
            "config": asdict(config)
        }
        
        save_vector_store(vector_store, config, metadata)
        
        # Final
        logger.info("\n" + "="*60)
        logger.success("ğŸ‰ VECTOR STORE OLUÅTURMA TAMAMLANDI!")
        logger.info("="*60)
        
        output_path = Path(config.output_dir)
        logger.info(f"ğŸ“ Vector store lokasyonu: {output_path}")
        logger.info(f"ğŸ“Š Ä°ÅŸlenen itemlar: {len(wardrobe_items)}")
        logger.info(f"ğŸ” Vector store tÃ¼rÃ¼: {config.vector_store_type}")
        logger.info("ğŸ“– KullanÄ±m iÃ§in README.md dosyasÄ±nÄ± inceleyin")
        logger.info("ğŸš€ Vector store artÄ±k RAG sisteminde kullanÄ±ma hazÄ±r!")
        
        # GPU memory temizleme
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            logger.info("ğŸ§¹ GPU memory temizlendi")
        
    except KeyboardInterrupt:
        logger.warning("âš ï¸ Vector store oluÅŸturma kullanÄ±cÄ± tarafÄ±ndan durduruldu")
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        sys.exit(1)
        
    except Exception as e:
        logger.error(f"âŒ Pipeline hatasÄ±: {str(e)}")
        logger.error(f"Traceback: {traceback.format_exc()}")
        
        # Cleanup on error
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        sys.exit(1)


if __name__ == "__main__":
    """
    Script doÄŸrudan Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda main fonksiyonunu Ã§aÄŸÄ±r
    
    KullanÄ±m Ã¶rnekleri:
    
    # FAISS ile temel kullanÄ±m
    python src/build_vector_store.py \\
        --input_data_path ./data/user_wardrobe.json \\
        --vector_store_type faiss \\
        --output_dir ./vector_stores
    
    # Pinecone ile kullanÄ±m
    python src/build_vector_store.py \\
        --input_data_path ./data/user_wardrobe.json \\
        --vector_store_type pinecone \\
        --pinecone_api_key your-api-key \\
        --pinecone_index_name aura-wardrobe
    
    # Ã–zel embedding modeli ile
    python src/build_vector_store.py \\
        --embedding_model_name sentence-transformers/all-mpnet-base-v2 \\
        --batch_size 16 \\
        --min_confidence 0.7
    """
    main()
