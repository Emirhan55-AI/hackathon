"""
Aura Conversational AI Service - FastAPI Main Application
=========================================================

Bu modÃ¼l, hibrit QLoRA + RAG sohbet asistanÄ±nÄ± FastAPI web sunucusu olarak sunar.
RAG Service'i HTTP API endpoints aracÄ±lÄ±ÄŸÄ±yla eriÅŸilebilir kÄ±lar.

Features:
- Hibrit QLoRA + RAG pipeline
- Real-time chat endpoints
- Personalized fashion advice
- WebSocket support for live chat
- User wardrobe integration
- Comprehensive error handling
"""

import os
import sys
import json
import logging
import asyncio
import time
from typing import Dict, List, Optional, Union, Any
from pathlib import Path
import traceback
from contextlib import asynccontextmanager

# A1. ModÃ¼l ve KÃ¼tÃ¼phane Ä°Ã§e Aktarma
# FastAPI ve ilgili kÃ¼tÃ¼phaneler
from fastapi import (
    FastAPI, 
    HTTPException, 
    Depends,
    BackgroundTasks,
    Request,
    Response,
    WebSocket,
    WebSocketDisconnect
)
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.trustedhost import TrustedHostMiddleware
from fastapi.responses import JSONResponse, StreamingResponse
from fastapi.exceptions import RequestValidationError
from starlette.exceptions import HTTPException as StarletteHTTPException
from starlette.middleware.base import BaseHTTPMiddleware

# Pydantic models for request/response validation
from pydantic import BaseModel, Field, validator
from pydantic.json import pydantic_encoder

# HTTP ve async operations
import uvicorn

# Parent directory'yi path'e ekle (RAG service modÃ¼llerini import edebilmek iÃ§in)
current_dir = Path(__file__).parent
parent_dir = current_dir.parent
sys.path.insert(0, str(parent_dir))

# Local imports - RAG Service modÃ¼lÃ¼
try:
    from src.rag_service import RAGService, RAGConfig, create_rag_service
    from src.rag_config_examples import get_rag_config
except ImportError as e:
    # Fallback import strategy
    try:
        from rag_service import RAGService, RAGConfig, create_rag_service
        from rag_config_examples import get_rag_config
    except ImportError:
        # Development import
        sys.path.insert(0, str(parent_dir.parent))
        from conversational_ai.src.rag_service import RAGService, RAGConfig, create_rag_service
        from conversational_ai.src.rag_config_examples import get_rag_config

# Logging configuration
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('conversational_ai_api.log')
    ]
)
logger = logging.getLogger(__name__)

# Global RAG service instance
global_rag_service: Optional[RAGService] = None

# API Configuration
API_TITLE = "Aura Conversational AI API"
API_DESCRIPTION = """
ğŸ¤– **Aura Yapay Zeka Platformu - Conversational AI Mikroservisi**

Bu API, hibrit QLoRA + RAG sistemi kullanarak kiÅŸiselleÅŸtirilmiÅŸ 
fashion sohbet asistanÄ± hizmeti sunar.

## Ã–zellikler:
- **Personalized Chat**: KullanÄ±cÄ± gardÄ±robuna Ã¶zel Ã¶neriler
- **Fashion Expertise**: Fine-tuned LLaMA model ile moda uzmanlÄ±ÄŸÄ±
- **Real-time Knowledge**: Vector store ile gÃ¼ncel gardÄ±rop bilgisi
- **Context Awareness**: Conversation history ve user preferences
- **WebSocket Support**: Real-time chat experience
- **Batch Processing**: Ã‡oklu mesaj desteÄŸi

## Sistem Mimarisi:
```
User Query â†’ Query Embedding â†’ Vector Search â†’ Context â†’ LLM â†’ Response
    â†“             â†“               â†“            â†“        â†“        â†“
  "Ne giysem?"  SentTrans      FAISS/Pine   Format   LLaMA   "Mavi ceket..."
```

## Desteklenen Ä°ÅŸlemler:
- KÄ±yafet Ã¶nerileri ve kombinasyon tavsiyeleri
- Renk uyumu ve stil danÄ±ÅŸmanlÄ±ÄŸÄ±
- Mevsim ve etkinlik bazlÄ± Ã¶neriler
- GardÄ±rop analizi ve eksik parÃ§a tespiti
- AlÄ±ÅŸveriÅŸ Ã¶nerileri ve trend analizi
"""
API_VERSION = "1.0.0"

# Request/Response Models
class ChatRequest(BaseModel):
    """Sohbet isteÄŸi iÃ§in Pydantic modeli"""
    query: str = Field(
        ...,
        min_length=1,
        max_length=1000,
        description="KullanÄ±cÄ±nÄ±n sohbet mesajÄ±",
        example="BugÃ¼n iÅŸ toplantÄ±sÄ± var, ne giysem iyi olur?"
    )
    user_id: str = Field(
        ...,
        min_length=1,
        max_length=100,
        description="KullanÄ±cÄ±nÄ±n benzersiz kimliÄŸi",
        example="user123"
    )
    session_id: Optional[str] = Field(
        default=None,
        description="Sohbet oturumu kimliÄŸi",
        example="session_abc123"
    )
    context: Optional[Dict[str, Any]] = Field(
        default=None,
        description="Ek baÄŸlam bilgileri (mevsim, etkinlik, vs.)",
        example={"season": "winter", "occasion": "business"}
    )
    
    @validator('query')
    def validate_query(cls, v):
        if not v.strip():
            raise ValueError('Query cannot be empty or whitespace only')
        return v.strip()


class ChatResponse(BaseModel):
    """Sohbet yanÄ±tÄ± iÃ§in Pydantic modeli"""
    success: bool = Field(description="Ä°ÅŸlem baÅŸarÄ± durumu")
    response: str = Field(description="Asistan yanÄ±tÄ±")
    user_id: str = Field(description="KullanÄ±cÄ± kimliÄŸi")
    session_id: Optional[str] = Field(description="Oturum kimliÄŸi")
    context_used: List[Dict[str, Any]] = Field(description="KullanÄ±lan baÄŸlam bilgileri")
    confidence: float = Field(description="YanÄ±t gÃ¼ven skoru")
    suggestions: Optional[List[str]] = Field(
        default=None,
        description="Ek Ã¶neriler veya sorular"
    )
    metadata: Dict[str, Any] = Field(description="Ä°ÅŸlem metadata'sÄ±")


class BatchChatRequest(BaseModel):
    """Toplu sohbet isteÄŸi"""
    messages: List[ChatRequest] = Field(
        ...,
        max_items=10,
        description="Toplu mesaj listesi (max 10)"
    )


class BatchChatResponse(BaseModel):
    """Toplu sohbet yanÄ±tÄ±"""
    success: bool = Field(description="Toplu iÅŸlem durumu")
    responses: List[ChatResponse] = Field(description="YanÄ±t listesi")
    processed_count: int = Field(description="Ä°ÅŸlenen mesaj sayÄ±sÄ±")
    failed_count: int = Field(description="BaÅŸarÄ±sÄ±z mesaj sayÄ±sÄ±")
    processing_time: float = Field(description="Toplam iÅŸlem sÃ¼resi")


class HealthResponse(BaseModel):
    """SaÄŸlÄ±k kontrolÃ¼ yanÄ±tÄ±"""
    status: str = Field(description="Servis durumu")
    service: str = Field(description="Servis adÄ±")
    model_loaded: bool = Field(description="Model yÃ¼klenme durumu")
    version: str = Field(description="API versiyonu")
    rag_service_stats: Dict[str, Any] = Field(description="RAG servis istatistikleri")
    timestamp: str = Field(description="Zaman damgasÄ±")


class ErrorResponse(BaseModel):
    """Hata yanÄ±tÄ±"""
    error: str = Field(description="Hata mesajÄ±")
    details: Optional[str] = Field(default=None, description="Hata detaylarÄ±")
    request_id: Optional[str] = Field(default=None, description="Ä°stek kimliÄŸi")
    timestamp: str = Field(description="Hata zamanÄ±")


# Custom middleware for logging and monitoring
class LoggingMiddleware(BaseHTTPMiddleware):
    """HTTP isteklerini loglayan middleware"""
    
    async def dispatch(self, request: Request, call_next):
        start_time = time.time()
        request_id = f"req_{int(time.time() * 1000)}"
        
        # Request logging
        logger.info(f"[{request_id}] Request: {request.method} {request.url}")
        
        try:
            response = await call_next(request)
            process_time = time.time() - start_time
            
            # Response logging
            logger.info(
                f"[{request_id}] Response: {response.status_code} | "
                f"Time: {process_time:.4f}s"
            )
            
            response.headers["X-Request-ID"] = request_id
            response.headers["X-Process-Time"] = str(process_time)
            return response
            
        except Exception as e:
            process_time = time.time() - start_time
            logger.error(f"[{request_id}] Request failed: {str(e)} | Time: {process_time:.4f}s")
            raise


# A2. FastAPI UygulamasÄ± ve RAG Servisinin YÃ¼klenmesi
@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    A2. Uygulama yaÅŸam dÃ¶ngÃ¼sÃ¼ yÃ¶netimi
    BaÅŸlangÄ±Ã§ta RAG servis yÃ¼kleme, kapanÄ±ÅŸta temizleme iÅŸlemleri
    """
    global global_rag_service
    
    logger.info("ğŸš€ Aura Conversational AI API baÅŸlatÄ±lÄ±yor...")
    
    # Startup: RAG Service yÃ¼kleme
    try:
        # Environment variables'dan config ayarlarÄ±
        config_name = os.getenv("RAG_CONFIG", "basic")  # basic, production, fast_inference vb.
        model_path = os.getenv("FINETUNED_MODEL_PATH", "./saved_models/aura_fashion_assistant")
        vector_store_path = os.getenv("VECTOR_STORE_PATH", "./vector_stores/wardrobe_faiss.index")
        
        logger.info(f"RAG Service yÃ¼kleniyor: config={config_name}")
        logger.info(f"Model path: {model_path}")
        logger.info(f"Vector store path: {vector_store_path}")
        
        # Config seÃ§imi
        try:
            config = get_rag_config(config_name)
            # Override paths from environment
            config.finetuned_model_path = model_path
            config.vector_store_path = vector_store_path
        except Exception as e:
            logger.warning(f"Config yÃ¼kleme hatasÄ±: {e}, basic config kullanÄ±lacak")
            config = get_rag_config("basic")
            config.finetuned_model_path = model_path
            config.vector_store_path = vector_store_path
        
        # RAG Service oluÅŸtur
        global_rag_service = RAGService(config)
        
        logger.info("âœ… RAG Service baÅŸarÄ±yla yÃ¼klendi!")
        
        # Service stats
        stats = global_rag_service.get_service_stats()
        logger.info(f"ğŸ“Š RAG Service Ä°statistikleri: {stats}")
        
    except Exception as e:
        logger.error(f"âŒ RAG Service yÃ¼kleme hatasÄ±: {str(e)}")
        logger.error(f"Traceback: {traceback.format_exc()}")
        # UygulamayÄ± durdurmayalÄ±m, hata endpoint'lerinde ele alalÄ±m
        global_rag_service = None
    
    yield  # Uygulama Ã§alÄ±ÅŸÄ±rken bekle
    
    # Shutdown: Temizleme iÅŸlemleri
    logger.info("ğŸ›‘ Aura Conversational AI API kapatÄ±lÄ±yor...")
    
    try:
        if global_rag_service is not None:
            # RAG Service cleanup
            global_rag_service.clear_cache()
            del global_rag_service
            global_rag_service = None
            
        logger.info("âœ… Temizleme iÅŸlemleri tamamlandÄ±")
        
    except Exception as e:
        logger.error(f"âŒ Temizleme hatasÄ±: {str(e)}")


# FastAPI uygulamasÄ± oluÅŸturma
app = FastAPI(
    title=API_TITLE,
    description=API_DESCRIPTION,
    version=API_VERSION,
    lifespan=lifespan,
    docs_url="/docs",
    redoc_url="/redoc",
    openapi_url="/openapi.json"
)

# A4. Middleware konfigÃ¼rasyonu
# CORS middleware - TarayÄ±cÄ± isteklerine izin ver
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Production'da specific domain'ler belirtilmeli
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE"],
    allow_headers=["*"],
)

# Trusted host middleware - GÃ¼venlik iÃ§in
app.add_middleware(
    TrustedHostMiddleware,
    allowed_hosts=["*"]  # Production'da specific host'lar belirtilmeli
)

# Custom logging middleware
app.add_middleware(LoggingMiddleware)


# A4. Global hata iÅŸleyicileri
@app.exception_handler(HTTPException)
async def http_exception_handler(request: Request, exc: HTTPException):
    """HTTP hatalarÄ± iÃ§in global handler"""
    logger.warning(f"HTTP Exception: {exc.status_code} - {exc.detail}")
    
    # RAG Service unavailable (503) hatalarÄ±nÄ± fallback'e yÃ¶nlendir
    if exc.status_code == 503 and "RAG Service" in str(exc.detail):
        # Chat endpoint'i iÃ§in fallback
        if request.url.path == "/chat":
            try:
                # Request body'yi okumaya Ã§alÄ±ÅŸ
                body = await request.body()
                if body:
                    import json
                    data = json.loads(body)
                    query = data.get("query", "Merhaba!")
                    user_id = data.get("user_id", "anonymous")
                    
                    fallback_response = generate_fallback_response(query, user_id)
                    
                    return JSONResponse(
                        status_code=200,
                        content=ChatResponse(
                            success=True,
                            response=fallback_response,
                            user_id=user_id,
                            session_id=data.get("session_id"),
                            context_used=[],
                            confidence=0.5,
                            suggestions=["Ne tÃ¼r kÄ±yafetler tercih ediyorsun?", "Hangi renkleri seviyorsun?"],
                            metadata={
                                "mode": "fallback",
                                "model_used": "fallback_chatbot",
                                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
                            }
                        ).dict()
                    )
            except Exception as fallback_error:
                logger.error(f"Fallback error: {fallback_error}")
    
    return JSONResponse(
        status_code=exc.status_code,
        content=ErrorResponse(
            error=exc.detail,
            timestamp=time.strftime("%Y-%m-%d %H:%M:%S")
        ).dict()
    )


@app.exception_handler(RequestValidationError)
async def validation_exception_handler(request: Request, exc: RequestValidationError):
    """Request validation hatalarÄ± iÃ§in handler"""
    logger.warning(f"Validation Error: {exc.errors()}")
    
    return JSONResponse(
        status_code=422,
        content=ErrorResponse(
            error="Request validation failed",
            details=str(exc.errors()),
            timestamp=time.strftime("%Y-%m-%d %H:%M:%S")
        ).dict()
    )


@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    """Genel hatalar iÃ§in global handler"""
    logger.error(f"Unhandled exception: {str(exc)}")
    logger.error(f"Traceback: {traceback.format_exc()}")
    
    return JSONResponse(
        status_code=500,
        content=ErrorResponse(
            error="Internal server error",
            details="Bir sistem hatasÄ± oluÅŸtu. LÃ¼tfen tekrar deneyin.",
            timestamp=time.strftime("%Y-%m-%d %H:%M:%S")
        ).dict()
    )


# Utility functions

def generate_fallback_response(query: str, user_id: str) -> str:
    """
    RAG service kullanÄ±lamadÄ±ÄŸÄ±nda basit fallback response'lar Ã¼retir
    
    Args:
        query: KullanÄ±cÄ± sorgusu
        user_id: KullanÄ±cÄ± ID'si
        
    Returns:
        str: Fallback yanÄ±tÄ±
    """
    import random
    
    # Basit anahtar kelime bazlÄ± yanÄ±tlar
    query_lower = query.lower()
    
    # Moda ile ilgili sorular
    if any(word in query_lower for word in ['ne giysem', 'ne giyeyim', 'kÄ±yafet', 'kombin']):
        responses = [
            f"Merhaba! Åu anda gardÄ±rop analiz sistemim yÃ¼kleniyor. Genel olarak, mevsime uygun rahat kÄ±yafetler Ã¶nerebilirim. Hangi mevsimde ve ne tÃ¼r bir etkinlik iÃ§in kÄ±yafet arÄ±yorsun?",
            f"Selam! Tam sistemi gÃ¼ncelliyorum ama yine de yardÄ±m edebilirim. Hangi renkleri seviyorsun ve rahat mÄ± ÅŸÄ±k mi bir stil tercih ediyorsun?",
            f"Merhaba {user_id}! Sistem birazdan hazÄ±r olacak. Bu sÄ±rada, Ã¶zel bir etkinlik mi var yoksa gÃ¼nlÃ¼k kombin mi arÄ±yorsun?"
        ]
    # Renk sorularÄ±
    elif any(word in query_lower for word in ['renk', 'color', 'hangi renk']):
        responses = [
            "Renk seÃ§imi kiÅŸisel zevke gÃ¶re deÄŸiÅŸir! Cilt tonuna ve saÃ§ rengine uygun renkler genellikle daha iyi durur. Hangi renkleri seviyorsun?",
            "GÃ¼zel bir soru! Mevsim renkleri de Ã¶nemli - ÅŸu anda hangi mevsimde yaÅŸÄ±yorsun?",
            "Renk kombinasyonlarÄ± Ã§ok eÄŸlenceli! Tek renk mi yoksa farklÄ± renkleri karÄ±ÅŸtÄ±rma mÄ± tercih ediyorsun?"
        ]
    # Genel selamlaÅŸma
    elif any(word in query_lower for word in ['merhaba', 'selam', 'hello', 'hi']):
        responses = [
            f"Merhaba {user_id}! Ben Aura, senin kiÅŸisel moda asistanÄ±n! Åu anda sistemim gÃ¼ncellenirken nasÄ±l yardÄ±m edebilirim?",
            f"Selam! Aura burada ğŸ‘‹ Moda konusunda sana yardÄ±m etmeye hazÄ±rÄ±m. Ne tÃ¼r sorular var?",
            f"Merhaba! KiÅŸisel moda asistanÄ±n Aura ile konuÅŸuyorsun. Hangi konuda yardÄ±ma ihtiyacÄ±n var?"
        ]
    # TeÅŸekkÃ¼r
    elif any(word in query_lower for word in ['teÅŸekkÃ¼r', 'saÄŸol', 'thanks', 'thank you']):
        responses = [
            "Rica ederim! Moda konusunda her zaman yardÄ±m etmeye hazÄ±rÄ±m ğŸ˜Š",
            "Ne demek! BaÅŸka sorularÄ±nÄ± bekliyorum âœ¨",
            "Sevindim yardÄ±m edebildiÄŸime! BaÅŸka neyde yardÄ±m edebilirim?"
        ]
    # VarsayÄ±lan yanÄ±tlar
    else:
        responses = [
            f"Merhaba {user_id}! Åu anda ana sistemim gÃ¼ncelleniyor ama gene de yardÄ±m etmeye Ã§alÄ±ÅŸayÄ±m. Moda ve kÄ±yafet konularÄ±nda sorularÄ±nÄ± sorabilirsin!",
            "Selam! Aura buradayÄ±m. Moda asistanÄ± Ã¶zelliklerim ÅŸu anda gÃ¼ncellenirken, genel moda sorularÄ±nÄ± yanÄ±tlamaya Ã§alÄ±ÅŸabilirim.",
            "Merhaba! KiÅŸisel gardÄ±rop analizim ÅŸu anda hazÄ±rlanÄ±yor. Bu arada moda tercihlerin hakkÄ±nda konuÅŸabiliriz!"
        ]
    
    return random.choice(responses)


def generate_suggestions(query: str, response: str) -> List[str]:
    """
    YanÄ±t bazÄ±nda ek Ã¶neriler Ã¼retir
    
    Args:
        query: KullanÄ±cÄ± sorgusu
        response: Asistan yanÄ±tÄ±
        
    Returns:
        List[str]: Ã–neriler listesi
    """
    suggestions = []
    
    # Query bazlÄ± Ã¶neriler
    if "renk" in query.lower():
        suggestions.extend([
            "Hangi renkler en Ã§ok yakÄ±ÅŸÄ±yor?",
            "Bu sezonun trend renkleri neler?"
        ])
    
    if "kombin" in query.lower() or "ne giysem" in query.lower():
        suggestions.extend([
            "Aksesuarlar nasÄ±l tamamlanÄ±r?",
            "Hangi ayakkabÄ± uygun olur?"
        ])
    
    if "iÅŸ" in query.lower() or "toplantÄ±" in query.lower():
        suggestions.extend([
            "Formal giyim kurallarÄ± neler?",
            "Ä°ÅŸ gardÄ±robumu nasÄ±l geliÅŸtiririm?"
        ])
    
    # Response bazlÄ± Ã¶neriler
    if "ceket" in response.lower():
        suggestions.append("Ceket bakÄ±mÄ± nasÄ±l yapÄ±lÄ±r?")
    
    if "ayakkabÄ±" in response.lower():
        suggestions.append("AyakkabÄ± kombinleri nasÄ±l olmalÄ±?")
    
    return suggestions[:3]  # Max 3 Ã¶neri


# A3. API Endpoint'lerinin TanÄ±mlanmasÄ±

@app.get("/", response_model=Dict[str, str])
async def root():
    """Ana sayfa - API bilgileri"""
    return {
        "message": "ğŸ¤– Aura Conversational AI API",
        "version": API_VERSION,
        "docs": "/docs",
        "health": "/health",
        "chat_endpoint": "/chat",
        "batch_endpoint": "/chat/batch"
    }


@app.get("/health", response_model=HealthResponse)
async def health_check():
    """
    A3a. Servis saÄŸlÄ±k kontrolÃ¼ endpoint'i
    
    Bu endpoint, servisin Ã§alÄ±ÅŸÄ±p Ã§alÄ±ÅŸmadÄ±ÄŸÄ±nÄ± ve RAG service'in
    yÃ¼klenip yÃ¼klenmediÄŸini kontrol eder.
    
    Returns:
        HealthResponse: Servis durumu bilgileri
    """
    logger.debug("Health check isteÄŸi alÄ±ndÄ±")
    
    service_loaded = global_rag_service is not None
    status = "OK" if service_loaded else "RAG_SERVICE_NOT_LOADED"
    
    # RAG service stats
    rag_stats = {}
    if global_rag_service:
        try:
            rag_stats = global_rag_service.get_service_stats()
        except Exception as e:
            rag_stats = {"error": str(e)}
    
    return HealthResponse(
        status=status,
        service="Conversational AI",
        model_loaded=service_loaded,
        version=API_VERSION,
        rag_service_stats=rag_stats,
        timestamp=time.strftime("%Y-%m-%d %H:%M:%S")
    )


@app.post("/chat", response_model=ChatResponse)
async def chat_endpoint(
    request: ChatRequest,
    background_tasks: BackgroundTasks = None
):
    """
    A3b. Ana sohbet endpoint'i
    
    Bu endpoint, kullanÄ±cÄ±nÄ±n mesajÄ±nÄ± alÄ±r, RAG pipeline'dan geÃ§irir
    ve kiÅŸiselleÅŸtirilmiÅŸ fashion advice yanÄ±tÄ± dÃ¶ndÃ¼rÃ¼r.
    
    Args:
        request: Sohbet isteÄŸi
        background_tasks: Arka plan gÃ¶revleri
        
    Returns:
        ChatResponse: Sohbet yanÄ±tÄ±
        
    Raises:
        HTTPException: Ã‡eÅŸitli hata durumlarÄ±nda
    """
    start_time = time.time()
    
    logger.info(f"Chat request: user={request.user_id}, query='{request.query[:50]}...'")
    
    try:
        # 1. RAG service kontrolÃ¼
        if global_rag_service is None:
            # Fallback response - RAG service yÃ¼klenemediÄŸinde
            logger.warning("RAG Service yÃ¼klÃ¼ deÄŸil, fallback response dÃ¶ndÃ¼rÃ¼lÃ¼yor")
            
            fallback_response = generate_fallback_response(request.query, request.user_id)
            processing_time = time.time() - start_time
            
            return ChatResponse(
                success=True,
                response=fallback_response,
                user_id=request.user_id,
                session_id=request.session_id,
                context_used=[],  # Fallback'de context yok
                confidence=0.5,   # DÃ¼ÅŸÃ¼k gÃ¼ven skoru
                suggestions=["Ne tÃ¼r kÄ±yafetler tercih ediyorsun?", "Hangi renkleri seviyorsun?", "Ã–zel bir etkinlik mi var?"],
                metadata={
                    "mode": "fallback",
                    "processing_time": processing_time,
                    "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                    "model_used": "fallback_chatbot"
                }
            )
        
        # 2. RAG pipeline ile yanÄ±t Ã¼retme
        logger.info("RAG pipeline baÅŸlatÄ±lÄ±yor...")
        
        rag_response = global_rag_service.generate_response(
            query=request.query,
            user_id=request.user_id
        )
        
        # 3. YanÄ±t iÅŸleme
        if not rag_response.get("success", False):
            raise HTTPException(
                status_code=500,
                detail=f"RAG pipeline hatasÄ±: {rag_response.get('error', 'Unknown error')}"
            )
        
        # 4. Ek Ã¶neriler Ã¼ret
        suggestions = generate_suggestions(request.query, rag_response["response"])
        
        # 5. Confidence score hesapla
        confidence = 0.9  # BaÅŸlangÄ±Ã§ deÄŸeri
        if rag_response.get("context_used"):
            # Context varsa confidence artÄ±r
            confidence = min(0.95, confidence + len(rag_response["context_used"]) * 0.05)
        
        # 6. Response formatla
        processing_time = time.time() - start_time
        
        response = ChatResponse(
            success=True,
            response=rag_response["response"],
            user_id=request.user_id,
            session_id=request.session_id,
            context_used=rag_response.get("context_used", []),
            confidence=confidence,
            suggestions=suggestions,
            metadata={
                "processing_time": processing_time,
                "rag_metadata": rag_response.get("metadata", {}),
                "context": request.context,
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
            }
        )
        
        logger.info(f"Chat response generated: {processing_time:.3f}s, confidence={confidence:.2f}")
        return response
        
    except HTTPException:
        # HTTP hatalarÄ± tekrar raise et
        raise
        
    except Exception as e:
        # Beklenmeyen hatalar
        processing_time = time.time() - start_time
        logger.error(f"Chat error: {str(e)} | Time: {processing_time:.4f}s")
        logger.error(f"Traceback: {traceback.format_exc()}")
        
        raise HTTPException(
            status_code=500,
            detail=f"Sohbet iÅŸlemi sÄ±rasÄ±nda hata oluÅŸtu: {str(e)}"
        )


@app.post("/chat/batch", response_model=BatchChatResponse)
async def batch_chat_endpoint(
    request: BatchChatRequest,
    background_tasks: BackgroundTasks = None
):
    """
    Toplu sohbet endpoint'i
    
    Bu endpoint, birden fazla mesajÄ± aynÄ± anda iÅŸler.
    
    Args:
        request: Toplu sohbet isteÄŸi
        background_tasks: Arka plan gÃ¶revleri
        
    Returns:
        BatchChatResponse: Toplu sohbet yanÄ±tÄ±
    """
    start_time = time.time()
    
    logger.info(f"Batch chat request: {len(request.messages)} messages")
    
    try:
        # RAG service kontrolÃ¼ ve fallback
        if global_rag_service is None:
            logger.warning("RAG Service yÃ¼klÃ¼ deÄŸil, batch fallback response dÃ¶ndÃ¼rÃ¼lÃ¼yor")
            # Batch fallback responses
            responses = []
            for message in request.messages:
                fallback_resp = generate_fallback_response(message.query, message.user_id)
                responses.append(ChatResponse(
                    success=True,
                    response=fallback_resp,
                    user_id=message.user_id,
                    session_id=message.session_id,
                    context_used=[],
                    confidence=0.5,
                    suggestions=["Ne tÃ¼r kÄ±yafetler tercih ediyorsun?"],
                    metadata={"mode": "fallback", "model_used": "fallback_chatbot"}
                ))
            
            return BatchChatResponse(
                success=True,
                responses=responses,
                total_processed=len(request.messages),
                failed_count=0,
                processing_time=time.time() - start_time,
                metadata={"mode": "batch_fallback"}
            )
        
        # Batch iÅŸleme
        responses = []
        failed_count = 0
        
        for i, message in enumerate(request.messages):
            logger.info(f"Processing batch message {i+1}/{len(request.messages)}")
            
            try:
                # Her mesaj iÃ§in chat endpoint'ini Ã§aÄŸÄ±r
                chat_response = await chat_endpoint(message)
                responses.append(chat_response)
                
            except Exception as e:
                logger.warning(f"Batch message {i+1} failed: {str(e)}")
                failed_count += 1
                
                # Hata response'u oluÅŸtur
                error_response = ChatResponse(
                    success=False,
                    response=f"Bu mesaj iÅŸlenirken hata oluÅŸtu: {str(e)}",
                    user_id=message.user_id,
                    session_id=message.session_id,
                    context_used=[],
                    confidence=0.0,
                    suggestions=[],
                    metadata={
                        "error": str(e),
                        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
                    }
                )
                responses.append(error_response)
        
        # Batch response oluÅŸtur
        processing_time = time.time() - start_time
        
        batch_response = BatchChatResponse(
            success=failed_count == 0,
            responses=responses,
            processed_count=len(responses),
            failed_count=failed_count,
            processing_time=processing_time
        )
        
        logger.info(f"Batch processing completed: {len(responses)} processed, {failed_count} failed")
        return batch_response
        
    except Exception as e:
        processing_time = time.time() - start_time
        logger.error(f"Batch chat error: {str(e)} | Time: {processing_time:.4f}s")
        
        raise HTTPException(
            status_code=500,
            detail=f"Toplu sohbet iÅŸlemi sÄ±rasÄ±nda hata oluÅŸtu: {str(e)}"
        )


@app.get("/chat/stats", response_model=Dict[str, Any])
async def get_chat_stats():
    """RAG service ve chat istatistiklerini dÃ¶ndÃ¼rÃ¼r"""
    if global_rag_service is None:
        # Fallback stats
        return {
            "api_version": API_VERSION,
            "service_status": "fallback_mode",
            "rag_service_loaded": False,
            "mode": "fallback_chatbot",
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "endpoints": ["/chat", "/chat/batch", "/health", "/stats"],
            "message": "RAG service yÃ¼klenmedi, fallback modunda Ã§alÄ±ÅŸÄ±yor"
        }
    
    try:
        rag_stats = global_rag_service.get_service_stats()
        
        api_stats = {
            "api_version": API_VERSION,
            "service_status": "active",
            "endpoints": [
                {"path": "/chat", "method": "POST", "description": "Single chat message"},
                {"path": "/chat/batch", "method": "POST", "description": "Batch chat messages"},
                {"path": "/chat/stats", "method": "GET", "description": "Service statistics"},
                {"path": "/health", "method": "GET", "description": "Health check"}
            ],
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
        }
        
        return {
            "rag_service": rag_stats,
            "api_service": api_stats
        }
        
    except Exception as e:
        logger.error(f"Stats error: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


# WebSocket support for real-time chat
@app.websocket("/ws/chat/{user_id}")
async def websocket_chat(websocket: WebSocket, user_id: str):
    """
    WebSocket endpoint'i - Real-time chat
    
    Args:
        websocket: WebSocket connection
        user_id: KullanÄ±cÄ± kimliÄŸi
    """
    await websocket.accept()
    logger.info(f"WebSocket connection established for user {user_id}")
    
    try:
        while True:
            # Receive message from client
            data = await websocket.receive_json()
            
            message = data.get("message", "")
            if not message:
                await websocket.send_json({
                    "error": "Empty message received"
                })
                continue
            
            # Create chat request
            chat_request = ChatRequest(
                query=message,
                user_id=user_id,
                session_id=data.get("session_id"),
                context=data.get("context", {})
            )
            
            try:
                # Process message
                response = await chat_endpoint(chat_request)
                
                # Send response back to client
                await websocket.send_json({
                    "success": True,
                    "response": response.response,
                    "confidence": response.confidence,
                    "suggestions": response.suggestions,
                    "context_used": len(response.context_used),
                    "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
                })
                
            except Exception as e:
                logger.error(f"WebSocket processing error: {str(e)}")
                await websocket.send_json({
                    "success": False,
                    "error": f"Mesaj iÅŸlenirken hata oluÅŸtu: {str(e)}"
                })
            
    except WebSocketDisconnect:
        logger.info(f"WebSocket connection closed for user {user_id}")
    except Exception as e:
        logger.error(f"WebSocket error for user {user_id}: {str(e)}")
        try:
            await websocket.send_json({
                "error": "WebSocket connection error"
            })
        except:
            pass


# A5. Uvicorn Sunucu BaÅŸlatÄ±cÄ±sÄ±
if __name__ == "__main__":
    """
    A5. Ana Ã§alÄ±ÅŸtÄ±rma bloÄŸu
    
    Bu blok, dosya doÄŸrudan Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda (python main.py) 
    uvicorn sunucusunu baÅŸlatÄ±r.
    """
    # Environment variables
    HOST = os.getenv("HOST", "0.0.0.0")
    PORT = int(os.getenv("PORT", 8003))
    DEBUG = os.getenv("DEBUG", "false").lower() == "true"
    WORKERS = int(os.getenv("WORKERS", 1))
    
    logger.info(f"ğŸš€ Aura Conversational AI API baÅŸlatÄ±lÄ±yor...")
    logger.info(f"ğŸ“ Host: {HOST}:{PORT}")
    logger.info(f"ğŸ› Debug mode: {DEBUG}")
    logger.info(f"ğŸ‘¥ Workers: {WORKERS}")
    
    # Uvicorn config
    uvicorn_config = {
        "host": HOST,
        "port": PORT,
        "reload": DEBUG,  # Development'ta auto-reload
        "workers": WORKERS if not DEBUG else 1,  # Debug'ta tek worker
        "log_level": "info",
        "access_log": True,
        "use_colors": True,
    }
    
    try:
        # Sunucuyu baÅŸlat
        uvicorn.run("main:app", **uvicorn_config)
        
    except KeyboardInterrupt:
        logger.info("ğŸ›‘ Sunucu durduruldu (Ctrl+C)")
        
    except Exception as e:
        logger.error(f"âŒ Sunucu baÅŸlatma hatasÄ±: {str(e)}")
        logger.error(f"Traceback: {traceback.format_exc()}")
        sys.exit(1)
