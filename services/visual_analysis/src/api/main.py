"""
FastAPI Main Application - DETR Visual Analysis Microservice for Aura Project
Bu mod√ºl, Aura projesinin g√∂rsel analiz mikroservisini FastAPI web sunucusu olarak sunar.
DETR tabanlƒ± fashion analysis modelini HTTP API endpoints aracƒ±lƒ±ƒüƒ±yla eri≈üilebilir kƒ±lar.
"""

import os
import sys
import json
import logging
import asyncio
import time
from typing import Dict, List, Optional, Union, Any
from pathlib import Path
import traceback
import tempfile
from contextlib import asynccontextmanager

# FastAPI ve ilgili k√ºt√ºphaneler
from fastapi import (
    FastAPI, 
    File, 
    UploadFile, 
    HTTPException, 
    Depends, 
    BackgroundTasks,
    Request,
    Response
)
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.trustedhost import TrustedHostMiddleware
from fastapi.responses import JSONResponse
from fastapi.exceptions import RequestValidationError
from starlette.exceptions import HTTPException as StarletteHTTPException
from starlette.middleware.base import BaseHTTPMiddleware

# Pydantic models for request/response validation
from pydantic import BaseModel, Field, validator
from pydantic.json import pydantic_encoder

# HTTP ve async operations
import uvicorn
import aiofiles

# PIL for image processing
from PIL import Image
import io

# Numerik k√ºt√ºphaneler
import numpy as np

# Parent directory'yi path'e ekle (inference mod√ºllerini import edebilmek i√ßin)
current_dir = Path(__file__).parent
parent_dir = current_dir.parent
sys.path.insert(0, str(parent_dir))

# Local imports - Aura project inference modules
try:
    from inference import (
        load_inference_model,
        run_inference,
        DEFAULT_CONFIDENCE_THRESHOLD,
        DEFAULT_MAX_DETECTIONS,
        FASHION_ATTRIBUTES
    )
    from data_loader import FASHIONPEDIA_CATEGORIES
    from model import TOTAL_CLASSES, FASHIONPEDIA_LABELS
except ImportError as e:
    # Fallback import strategy
    sys.path.insert(0, str(parent_dir.parent))
    try:
        from src.inference import (
            load_inference_model,
            run_inference,
            DEFAULT_CONFIDENCE_THRESHOLD,
            DEFAULT_MAX_DETECTIONS,
            FASHION_ATTRIBUTES
        )
        from src.data_loader import FASHIONPEDIA_CATEGORIES
        from src.model import TOTAL_CLASSES, FASHIONPEDIA_LABELS
    except ImportError:
        # Son √ßare - relatif import
        from ..inference import (
            load_inference_model,
            run_inference,
            DEFAULT_CONFIDENCE_THRESHOLD,
            DEFAULT_MAX_DETECTIONS,
            FASHION_ATTRIBUTES
        )
        from ..data_loader import FASHIONPEDIA_CATEGORIES
        from ..model import TOTAL_CLASSES, FASHIONPEDIA_LABELS

# Logging configuration
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('visual_analysis_api.log')
    ]
)
logger = logging.getLogger(__name__)

# Global variables for model and processor
global_model = None
global_processor = None
global_model_info = {}

# API Configuration
API_TITLE = "Aura Visual Analysis API"
API_DESCRIPTION = """
üîç **Aura Yapay Zeka Platformu - G√∂rsel Analiz Mikroservisi**

Bu API, DETR (Detection Transformer) tabanlƒ± derin √∂ƒürenme modeli kullanarak 
fashion g√∂r√ºnt√ºlerinin analizini ger√ßekle≈ütirir.

## √ñzellikler:
- **Fashion Item Detection**: Giyim e≈üyalarƒ± ve aksesuarlarƒ± algƒ±lama
- **Attribute Analysis**: Renk, desen, stil ve malzeme analizi  
- **Segmentation**: Piksel seviyesinde segmentasyon maskeleri
- **Confidence Scoring**: Her detection i√ßin g√ºven skorlarƒ±
- **Batch Processing**: √áoklu g√∂r√ºnt√º analizi desteƒüi

## Desteklenen Fashion Kategorileri:
- √úst giyim (g√∂mlek, ti≈ü√∂rt, kazak, ceket vb.)
- Alt giyim (pantolon, etek, ≈üort vb.)
- Ayakkabƒ± ve aksesuarlar
- Desenler ve detaylar (d√ºƒüme, fermuar, cep vb.)

Toplam **294 Fashionpedia kategorisi** + 1 background class = **295 sƒ±nƒ±f**
"""
API_VERSION = "1.0.0"

# Supported image formats
SUPPORTED_IMAGE_FORMATS = {".jpg", ".jpeg", ".png", ".bmp", ".tiff", ".webp"}
MAX_FILE_SIZE = 10 * 1024 * 1024  # 10MB limit

# API Models (Request/Response schemas)
class AnalysisRequest(BaseModel):
    """G√∂rsel analiz isteƒüi i√ßin Pydantic modeli"""
    confidence_threshold: float = Field(
        default=DEFAULT_CONFIDENCE_THRESHOLD,
        ge=0.1, 
        le=1.0, 
        description="Minimum g√ºven skoru threshold'u (0.1-1.0)"
    )
    max_detections: int = Field(
        default=DEFAULT_MAX_DETECTIONS,
        ge=1, 
        le=200, 
        description="Maksimum detection sayƒ±sƒ± (1-200)"
    )
    return_masks: bool = Field(
        default=True,
        description="Segmentation maskelerini d√∂nd√ºr"
    )
    include_attributes: bool = Field(
        default=True,
        description="Fashion √∂zniteliklerini (renk, desen vb.) dahil et"
    )


class DetectionResult(BaseModel):
    """Tek bir detection sonucu"""
    label: str = Field(description="Fashion kategori etiketi")
    confidence: float = Field(description="G√ºven skoru (0-1)")
    bbox: List[float] = Field(description="Bounding box [x, y, width, height]")
    area: float = Field(description="Detection alanƒ± (piksel)")
    category_id: int = Field(description="Fashionpedia kategori ID'si")
    attributes: Optional[Dict[str, Any]] = Field(
        default=None,
        description="Fashion √∂zellikleri (renk, desen, stil, malzeme)"
    )
    mask: Optional[List[List[int]]] = Field(
        default=None,
        description="Segmentation maskesi (opsiyonel)"
    )


class AnalysisResponse(BaseModel):
    """G√∂rsel analiz yanƒ±tƒ±"""
    success: bool = Field(description="ƒ∞≈ülem ba≈üarƒ± durumu")
    detections: List[DetectionResult] = Field(description="Tespit edilen fashion itemlar")
    summary: Dict[str, Any] = Field(description="Analiz √∂zeti")
    metadata: Dict[str, Any] = Field(description="ƒ∞≈ülem metadata'sƒ±")
    processing_time: float = Field(description="ƒ∞≈ülem s√ºresi (saniye)")
    model_info: Dict[str, str] = Field(description="Model bilgileri")


class HealthResponse(BaseModel):
    """Saƒülƒ±k kontrol√º yanƒ±tƒ±"""
    status: str = Field(description="Servis durumu")
    model_loaded: bool = Field(description="Model y√ºklenme durumu")
    version: str = Field(description="API versiyonu")
    timestamp: str = Field(description="Zaman damgasƒ±")
    supported_formats: List[str] = Field(description="Desteklenen g√∂r√ºnt√º formatlarƒ±")


class ErrorResponse(BaseModel):
    """Hata yanƒ±tƒ±"""
    error: str = Field(description="Hata mesajƒ±")
    details: Optional[str] = Field(default=None, description="Hata detaylarƒ±")
    timestamp: str = Field(description="Hata zamanƒ±")


# Custom middleware for logging and monitoring
class LoggingMiddleware(BaseHTTPMiddleware):
    """HTTP isteklerini loglayan middleware"""
    
    async def dispatch(self, request: Request, call_next):
        start_time = time.time()
        
        # Request logging
        logger.info(f"Request: {request.method} {request.url}")
        
        try:
            response = await call_next(request)
            process_time = time.time() - start_time
            
            # Response logging
            logger.info(
                f"Response: {response.status_code} | "
                f"Time: {process_time:.4f}s | "
                f"Size: {response.headers.get('content-length', 'unknown')}"
            )
            
            response.headers["X-Process-Time"] = str(process_time)
            return response
            
        except Exception as e:
            process_time = time.time() - start_time
            logger.error(f"Request failed: {str(e)} | Time: {process_time:.4f}s")
            raise


# Application lifecycle management
@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    A2. Uygulama ya≈üam d√∂ng√ºs√º y√∂netimi
    Ba≈ülangƒ±√ßta model y√ºkleme, kapanƒ±≈üta temizleme i≈ülemleri
    """
    global global_model, global_processor, global_model_info
    
    logger.info("üöÄ Aura Visual Analysis API ba≈ülatƒ±lƒ±yor...")
    
    # Startup: Model y√ºkleme
    try:
        model_path = os.getenv(
            "MODEL_PATH", 
            "./saved_models/detr_fashionpedia.pth"
        )
        
        logger.info(f"Model y√ºkleniyor: {model_path}")
        
        # Eƒüer model dosyasƒ± yoksa, pre-trained model kullan
        if not os.path.exists(model_path):
            logger.warning(f"Model dosyasƒ± bulunamadƒ±: {model_path}")
            logger.info("Pre-trained DETR modeli kullanƒ±lacak")
            
            # load_inference_model fonksiyonunu pre-trained model i√ßin √ßaƒüƒ±r
            global_model, global_processor = load_inference_model(
                model_path="facebook/detr-resnet-50-panoptic"
            )
        else:
            global_model, global_processor = load_inference_model(model_path)
        
        # Model bilgilerini kaydet
        global_model_info = {
            "model_path": model_path,
            "total_classes": TOTAL_CLASSES,
            "categories_count": len(FASHIONPEDIA_CATEGORIES),
            "model_type": "DETR (Detection Transformer)",
            "framework": "PyTorch + Hugging Face Transformers"
        }
        
        logger.info("‚úÖ Model ba≈üarƒ±yla y√ºklendi!")
        logger.info(f"üìä Model ƒ∞statistikleri: {global_model_info}")
        
    except Exception as e:
        logger.error(f"‚ùå Model y√ºkleme hatasƒ±: {str(e)}")
        logger.error(f"Traceback: {traceback.format_exc()}")
        # Uygulamayƒ± durdurmayalƒ±m, hata endpoint'lerinde ele alalƒ±m
        global_model = None
        global_processor = None
    
    yield  # Uygulama √ßalƒ±≈üƒ±rken bekle
    
    # Shutdown: Temizleme i≈ülemleri
    logger.info("üõë Aura Visual Analysis API kapatƒ±lƒ±yor...")
    
    try:
        # Model memory'den temizle
        if global_model is not None:
            del global_model
            global_model = None
            
        if global_processor is not None:
            del global_processor
            global_processor = None
            
        # GPU memory temizle (eƒüer CUDA kullanƒ±lƒ±yorsa)
        if hasattr(torch, 'cuda') and torch.cuda.is_available():
            torch.cuda.empty_cache()
            
        logger.info("‚úÖ Temizleme i≈ülemleri tamamlandƒ±")
        
    except Exception as e:
        logger.error(f"‚ùå Temizleme hatasƒ±: {str(e)}")


# A2. FastAPI uygulamasƒ± olu≈üturma
app = FastAPI(
    title=API_TITLE,
    description=API_DESCRIPTION,
    version=API_VERSION,
    lifespan=lifespan,
    docs_url="/docs",
    redoc_url="/redoc",
    openapi_url="/openapi.json"
)

# A4. Middleware konfig√ºrasyonu
# CORS middleware - Tarayƒ±cƒ± isteklerine izin ver
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Production'da specific domain'ler belirtilmeli
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE"],
    allow_headers=["*"],
)

# Trusted host middleware - G√ºvenlik i√ßin
app.add_middleware(
    TrustedHostMiddleware,
    allowed_hosts=["*"]  # Production'da specific host'lar belirtilmeli
)

# Custom logging middleware
app.add_middleware(LoggingMiddleware)


# A4. Global hata i≈üleyicileri
@app.exception_handler(HTTPException)
async def http_exception_handler(request: Request, exc: HTTPException):
    """HTTP hatalarƒ± i√ßin global handler"""
    logger.warning(f"HTTP Exception: {exc.status_code} - {exc.detail}")
    
    return JSONResponse(
        status_code=exc.status_code,
        content=ErrorResponse(
            error=exc.detail,
            timestamp=time.strftime("%Y-%m-%d %H:%M:%S")
        ).dict()
    )


@app.exception_handler(RequestValidationError)
async def validation_exception_handler(request: Request, exc: RequestValidationError):
    """Request validation hatalarƒ± i√ßin handler"""
    logger.warning(f"Validation Error: {exc.errors()}")
    
    return JSONResponse(
        status_code=422,
        content=ErrorResponse(
            error="Request validation failed",
            details=str(exc.errors()),
            timestamp=time.strftime("%Y-%m-%d %H:%M:%S")
        ).dict()
    )


@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    """Genel hatalar i√ßin global handler"""
    logger.error(f"Unhandled exception: {str(exc)}")
    logger.error(f"Traceback: {traceback.format_exc()}")
    
    return JSONResponse(
        status_code=500,
        content=ErrorResponse(
            error="Internal server error",
            details="Bir sistem hatasƒ± olu≈ütu. L√ºtfen tekrar deneyin.",
            timestamp=time.strftime("%Y-%m-%d %H:%M:%S")
        ).dict()
    )


# Utility functions
def validate_image_file(file: UploadFile) -> None:
    """
    Y√ºklenen dosyanƒ±n ge√ßerli bir g√∂r√ºnt√º dosyasƒ± olup olmadƒ±ƒüƒ±nƒ± kontrol eder
    
    Args:
        file: Y√ºklenen dosya
        
    Raises:
        HTTPException: Ge√ßersiz dosya durumunda
    """
    # Dosya boyutu kontrol√º
    if file.size and file.size > MAX_FILE_SIZE:
        raise HTTPException(
            status_code=413,
            detail=f"Dosya boyutu √ßok b√ºy√ºk. Maksimum: {MAX_FILE_SIZE // (1024*1024)}MB"
        )
    
    # Dosya uzantƒ±sƒ± kontrol√º
    if file.filename:
        file_extension = Path(file.filename).suffix.lower()
        if file_extension not in SUPPORTED_IMAGE_FORMATS:
            raise HTTPException(
                status_code=415,
                detail=f"Desteklenmeyen dosya formatƒ±. Desteklenen: {list(SUPPORTED_IMAGE_FORMATS)}"
            )


def check_model_availability() -> None:
    """
    Modelin y√ºkl√º olup olmadƒ±ƒüƒ±nƒ± kontrol eder
    
    Raises:
        HTTPException: Model y√ºkl√º deƒüilse
    """
    if global_model is None or global_processor is None:
        raise HTTPException(
            status_code=503,
            detail="Model hen√ºz y√ºklenmedi veya y√ºkleme ba≈üarƒ±sƒ±z. L√ºtfen daha sonra tekrar deneyin."
        )


async def save_uploaded_file(file: UploadFile) -> str:
    """
    Y√ºklenen dosyayƒ± ge√ßici olarak kaydeder
    
    Args:
        file: Y√ºklenen dosya
        
    Returns:
        str: Kaydedilen dosyanƒ±n yolu
    """
    # Ge√ßici dosya olu≈ütur
    suffix = Path(file.filename or "image").suffix
    
    with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp_file:
        content = await file.read()
        tmp_file.write(content)
        tmp_file_path = tmp_file.name
    
    return tmp_file_path


# A3. API Endpoints

@app.get("/", response_model=Dict[str, str])
async def root():
    """Ana sayfa - API bilgileri"""
    return {
        "message": "üîç Aura Visual Analysis API",
        "version": API_VERSION,
        "docs": "/docs",
        "health": "/health",
        "analyze_endpoint": "/analyze"
    }


@app.get("/health", response_model=HealthResponse)
async def health_check():
    """
    A3a. Servis saƒülƒ±k kontrol√º endpoint'i
    
    Bu endpoint, servisin √ßalƒ±≈üƒ±p √ßalƒ±≈ümadƒ±ƒüƒ±nƒ± ve modelin 
    y√ºklenip y√ºklenmediƒüini kontrol eder.
    
    Returns:
        HealthResponse: Servis durumu bilgileri
    """
    logger.debug("Health check isteƒüi alƒ±ndƒ±")
    
    model_loaded = global_model is not None and global_processor is not None
    status = "OK" if model_loaded else "MODEL_NOT_LOADED"
    
    return HealthResponse(
        status=status,
        model_loaded=model_loaded,
        version=API_VERSION,
        timestamp=time.strftime("%Y-%m-%d %H:%M:%S"),
        supported_formats=list(SUPPORTED_IMAGE_FORMATS)
    )


@app.get("/model/info", response_model=Dict[str, Any])
async def get_model_info():
    """Model hakkƒ±nda detaylƒ± bilgi d√∂nd√ºr√ºr"""
    check_model_availability()
    
    return {
        "model_info": global_model_info,
        "categories": FASHIONPEDIA_CATEGORIES,
        "total_categories": len(FASHIONPEDIA_CATEGORIES),
        "fashion_attributes": FASHION_ATTRIBUTES,
        "default_settings": {
            "confidence_threshold": DEFAULT_CONFIDENCE_THRESHOLD,
            "max_detections": DEFAULT_MAX_DETECTIONS
        }
    }


@app.post("/analyze", response_model=AnalysisResponse)
async def analyze_image(
    file: UploadFile = File(..., description="Analiz edilecek g√∂r√ºnt√º dosyasƒ±"),
    confidence_threshold: float = DEFAULT_CONFIDENCE_THRESHOLD,
    max_detections: int = DEFAULT_MAX_DETECTIONS,
    return_masks: bool = True,
    include_attributes: bool = True,
    background_tasks: BackgroundTasks = None
):
    """
    A3b. Ana g√∂r√ºnt√º analizi endpoint'i
    
    Bu endpoint, kullanƒ±cƒ±nƒ±n y√ºklediƒüi g√∂r√ºnt√ºy√º analiz eder ve
    fashion itemlarƒ±, √∂znitelikleri ve segmentation maskelerini d√∂nd√ºr√ºr.
    
    Args:
        file: Y√ºklenen g√∂r√ºnt√º dosyasƒ±
        confidence_threshold: Minimum g√ºven skoru
        max_detections: Maksimum detection sayƒ±sƒ±
        return_masks: Segmentation maskelerini d√∂nd√ºr
        include_attributes: Fashion √∂zniteliklerini dahil et
        background_tasks: Arka plan g√∂revleri
        
    Returns:
        AnalysisResponse: Analiz sonu√ßlarƒ±
        
    Raises:
        HTTPException: √áe≈üitli hata durumlarƒ±nda
    """
    start_time = time.time()
    temp_file_path = None
    
    logger.info(f"G√∂r√ºnt√º analizi ba≈ülatƒ±lƒ±yor: {file.filename}")
    
    try:
        # 1. Model kontrol√º
        check_model_availability()
        
        # 2. Dosya doƒürulama
        validate_image_file(file)
        
        # 3. Parametre doƒürulama
        if not (0.1 <= confidence_threshold <= 1.0):
            raise HTTPException(
                status_code=422,
                detail="confidence_threshold 0.1-1.0 arasƒ±nda olmalƒ±dƒ±r"
            )
        
        if not (1 <= max_detections <= 200):
            raise HTTPException(
                status_code=422,
                detail="max_detections 1-200 arasƒ±nda olmalƒ±dƒ±r"
            )
        
        # 4. Dosyayƒ± ge√ßici olarak kaydet
        temp_file_path = await save_uploaded_file(file)
        
        # 5. G√∂r√ºnt√ºy√º y√ºkle ve doƒürula
        try:
            pil_image = Image.open(temp_file_path).convert("RGB")
            original_size = pil_image.size
            logger.info(f"G√∂r√ºnt√º y√ºklendi: {original_size[0]}x{original_size[1]}")
        except Exception as e:
            raise HTTPException(
                status_code=400,
                detail=f"G√∂r√ºnt√º dosyasƒ± bozuk veya okunamƒ±yor: {str(e)}"
            )
        
        # 6. DETR inference √ßalƒ±≈ütƒ±r
        logger.info("DETR inference ba≈ülatƒ±lƒ±yor...")
        
        inference_results = run_inference(
            model=global_model,
            image_processor=global_processor,
            image=pil_image,
            confidence_threshold=confidence_threshold,
            max_detections=max_detections,
            return_masks=return_masks,
            return_raw_output=False
        )
        
        logger.info(f"Inference tamamlandƒ±: {len(inference_results.get('detections', []))} detection")
        
        # 7. Sonu√ßlarƒ± API formatƒ±na d√∂n√º≈üt√ºr
        detections = []
        
        for det in inference_results.get('detections', []):
            detection_result = DetectionResult(
                label=det.get('label', 'unknown'),
                confidence=det.get('confidence', 0.0),
                bbox=det.get('bbox', [0, 0, 0, 0]),
                area=det.get('area', 0.0),
                category_id=det.get('category_id', 0),
                attributes=det.get('attributes') if include_attributes else None,
                mask=det.get('mask') if return_masks else None
            )
            detections.append(detection_result)
        
        # 8. √ñzet bilgilerini hazƒ±rla
        summary = {
            "total_detections": len(detections),
            "unique_categories": len(set(d.label for d in detections)),
            "average_confidence": sum(d.confidence for d in detections) / len(detections) if detections else 0.0,
            "image_dimensions": original_size,
            "categories_found": list(set(d.label for d in detections))
        }
        
        # Attribute summary (eƒüer dahil edilmi≈üse)
        if include_attributes and detections:
            summary["attributes_summary"] = {}
            for attr_type in ["colors", "patterns", "styles", "materials"]:
                found_attrs = set()
                for det in detections:
                    if det.attributes and attr_type in det.attributes:
                        if isinstance(det.attributes[attr_type], list):
                            found_attrs.update(det.attributes[attr_type])
                        else:
                            found_attrs.add(det.attributes[attr_type])
                summary["attributes_summary"][attr_type] = list(found_attrs)
        
        # 9. Metadata hazƒ±rla
        processing_time = time.time() - start_time
        
        metadata = {
            "processing_time": processing_time,
            "image_filename": file.filename,
            "image_size": file.size,
            "parameters_used": {
                "confidence_threshold": confidence_threshold,
                "max_detections": max_detections,
                "return_masks": return_masks,
                "include_attributes": include_attributes
            },
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
        }
        
        logger.info(f"Analiz tamamlandƒ±: {processing_time:.4f}s")
        
        # 10. Response olu≈ütur
        response = AnalysisResponse(
            success=True,
            detections=detections,
            summary=summary,
            metadata=metadata,
            processing_time=processing_time,
            model_info=global_model_info
        )
        
        # 11. Arka plan g√∂revi: ge√ßici dosyayƒ± sil
        if background_tasks and temp_file_path:
            background_tasks.add_task(cleanup_temp_file, temp_file_path)
        
        return response
        
    except HTTPException:
        # HTTP hatalarƒ± tekrar raise et
        raise
        
    except Exception as e:
        # Beklenmeyen hatalar
        processing_time = time.time() - start_time
        logger.error(f"Analiz hatasƒ±: {str(e)} | Time: {processing_time:.4f}s")
        logger.error(f"Traceback: {traceback.format_exc()}")
        
        raise HTTPException(
            status_code=500,
            detail=f"G√∂r√ºnt√º analizi sƒ±rasƒ±nda hata olu≈ütu: {str(e)}"
        )
    
    finally:
        # Ge√ßici dosyayƒ± temizle (eƒüer background task kullanƒ±lmƒ±yorsa)
        if temp_file_path and not background_tasks:
            try:
                os.unlink(temp_file_path)
            except Exception as e:
                logger.warning(f"Ge√ßici dosya silinemedi: {e}")


@app.post("/analyze/batch", response_model=List[AnalysisResponse])
async def analyze_images_batch(
    files: List[UploadFile] = File(..., description="Analiz edilecek g√∂r√ºnt√º dosyalarƒ± listesi"),
    confidence_threshold: float = DEFAULT_CONFIDENCE_THRESHOLD,
    max_detections: int = DEFAULT_MAX_DETECTIONS,
    return_masks: bool = False,  # Batch'te mask'ler varsayƒ±lan olarak kapalƒ±
    include_attributes: bool = True,
    background_tasks: BackgroundTasks = None
):
    """
    √áoklu g√∂r√ºnt√º analizi endpoint'i
    
    Bu endpoint, birden fazla g√∂r√ºnt√ºy√º aynƒ± anda analiz eder.
    B√ºy√ºk batch'ler i√ßin performans optimizasyonu i√ßerir.
    
    Args:
        files: Analiz edilecek g√∂r√ºnt√º dosyalarƒ± listesi
        confidence_threshold: Minimum g√ºven skoru
        max_detections: Maksimum detection sayƒ±sƒ±  
        return_masks: Segmentation maskelerini d√∂nd√ºr
        include_attributes: Fashion √∂zniteliklerini dahil et
        background_tasks: Arka plan g√∂revleri
        
    Returns:
        List[AnalysisResponse]: Her g√∂r√ºnt√º i√ßin analiz sonu√ßlarƒ±
    """
    logger.info(f"Batch analiz ba≈ülatƒ±lƒ±yor: {len(files)} dosya")
    
    # Batch size kontrol√º
    if len(files) > 20:  # Maksimum batch size
        raise HTTPException(
            status_code=413,
            detail="Tek seferde en fazla 20 g√∂r√ºnt√º analiz edilebilir"
        )
    
    check_model_availability()
    
    results = []
    
    for i, file in enumerate(files):
        logger.info(f"Batch analiz: {i+1}/{len(files)} - {file.filename}")
        
        try:
            # Her dosya i√ßin analyze_image fonksiyonunu √ßaƒüƒ±r
            result = await analyze_image(
                file=file,
                confidence_threshold=confidence_threshold,
                max_detections=max_detections,
                return_masks=return_masks,
                include_attributes=include_attributes,
                background_tasks=background_tasks
            )
            results.append(result)
            
        except Exception as e:
            # Hatalƒ± dosyalar i√ßin hata response'u olu≈ütur
            logger.warning(f"Batch'te dosya hatasƒ±: {file.filename} - {str(e)}")
            
            error_result = AnalysisResponse(
                success=False,
                detections=[],
                summary={"error": str(e), "filename": file.filename},
                metadata={"timestamp": time.strftime("%Y-%m-%d %H:%M:%S")},
                processing_time=0.0,
                model_info=global_model_info
            )
            results.append(error_result)
    
    logger.info(f"Batch analiz tamamlandƒ±: {len(results)} sonu√ß")
    return results


# Utility endpoints
@app.get("/categories", response_model=Dict[str, Any])
async def get_categories():
    """Desteklenen fashion kategorilerini d√∂nd√ºr√ºr"""
    return {
        "categories": FASHIONPEDIA_CATEGORIES,
        "total_count": len(FASHIONPEDIA_CATEGORIES),
        "attributes": FASHION_ATTRIBUTES
    }


@app.get("/stats", response_model=Dict[str, Any])
async def get_api_stats():
    """API istatistiklerini d√∂nd√ºr√ºr"""
    # Bu √∂rnekte basit istatistikler, production'da ger√ßek metrics kullanƒ±labilir
    return {
        "api_version": API_VERSION,
        "model_loaded": global_model is not None,
        "supported_formats": list(SUPPORTED_IMAGE_FORMATS),
        "max_file_size_mb": MAX_FILE_SIZE // (1024 * 1024),
        "max_batch_size": 20,
        "endpoints": [
            {"path": "/", "method": "GET", "description": "Root endpoint"},
            {"path": "/health", "method": "GET", "description": "Health check"},
            {"path": "/analyze", "method": "POST", "description": "Single image analysis"},
            {"path": "/analyze/batch", "method": "POST", "description": "Batch image analysis"},
            {"path": "/categories", "method": "GET", "description": "Fashion categories"},
            {"path": "/model/info", "method": "GET", "description": "Model information"}
        ]
    }


# Background task functions
def cleanup_temp_file(file_path: str):
    """Ge√ßici dosyayƒ± temizleyen arka plan g√∂revi"""
    try:
        if os.path.exists(file_path):
            os.unlink(file_path)
            logger.debug(f"Ge√ßici dosya silindi: {file_path}")
    except Exception as e:
        logger.warning(f"Ge√ßici dosya silinemedi {file_path}: {e}")


# A5. Uvicorn sunucu ba≈ülatƒ±cƒ±sƒ±
if __name__ == "__main__":
    """
    A5. Ana √ßalƒ±≈ütƒ±rma bloƒüu
    
    Bu blok, dosya doƒürudan √ßalƒ±≈ütƒ±rƒ±ldƒ±ƒüƒ±nda (python main.py) 
    uvicorn sunucusunu ba≈ülatƒ±r.
    """
    # Environment variables
    HOST = os.getenv("HOST", "0.0.0.0")
    PORT = int(os.getenv("PORT", 8000))
    DEBUG = os.getenv("DEBUG", "false").lower() == "true"
    WORKERS = int(os.getenv("WORKERS", 1))
    
    logger.info(f"üöÄ Aura Visual Analysis API ba≈ülatƒ±lƒ±yor...")
    logger.info(f"üìç Host: {HOST}:{PORT}")
    logger.info(f"üêõ Debug mode: {DEBUG}")
    logger.info(f"üë• Workers: {WORKERS}")
    
    # Uvicorn config
    uvicorn_config = {
        "host": HOST,
        "port": PORT,
        "reload": DEBUG,  # Development'ta auto-reload
        "workers": WORKERS if not DEBUG else 1,  # Debug'ta tek worker
        "log_level": "info",
        "access_log": True,
        "use_colors": True,
    }
    
    try:
        # Sunucuyu ba≈ülat
        uvicorn.run("main:app", **uvicorn_config)
        
    except KeyboardInterrupt:
        logger.info("üõë Sunucu durduruldu (Ctrl+C)")
        
    except Exception as e:
        logger.error(f"‚ùå Sunucu ba≈ülatma hatasƒ±: {str(e)}")
        logger.error(f"Traceback: {traceback.format_exc()}")
        sys.exit(1)
